{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMoiHwjJsauqkPtuqfaGYJi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rugiyya1/Churn_analysis_of_a_Bank_Kaggle_competition/blob/main/Binary_classification_with_a_bank_churn_dataset_Kaggle_competition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJhjH5ZFMH8J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# %matplotlib notebook\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
        "# plt.rcParams['figure.dpi'] = 100\n",
        "sns.set_style(\"darkgrid\")\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.warn(\"this will not show\")\n",
        "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# algorithms\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "from lightgbm.sklearn import LGBMClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, RocCurveDisplay"
      ],
      "metadata": {
        "id": "1Dlv5UVcrrUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import FunctionTransformer, StandardScaler, LabelEncoder\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA, TruncatedSVD\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "metadata": {
        "id": "krscRT9fU2PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/train.csv', index_col='id').astype({'IsActiveMember' : np.uint8, 'HasCrCard' : np.uint8})\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "BIDLjsISMczj",
        "outputId": "1e5a9951-0a70-496c-a45e-72105f181bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n",
              "id                                                                           \n",
              "0     15674932  Okwudilichukwu          668    France   Male 33.00       3   \n",
              "1     15749177   Okwudiliolisa          627    France   Male 33.00       1   \n",
              "2     15694510           Hsueh          678    France   Male 40.00      10   \n",
              "3     15741417             Kao          581    France   Male 34.00       2   \n",
              "4     15766172       Chiemenam          716     Spain   Male 33.00       5   \n",
              "\n",
              "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
              "id                                                                        \n",
              "0       0.00              2          1               0        181449.97   \n",
              "1       0.00              2          1               1         49503.50   \n",
              "2       0.00              2          1               0        184866.69   \n",
              "3  148882.54              1          1               1         84560.88   \n",
              "4       0.00              2          1               1         15068.83   \n",
              "\n",
              "    Exited  \n",
              "id          \n",
              "0        0  \n",
              "1        0  \n",
              "2        0  \n",
              "3        0  \n",
              "4        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f145adb7-4c75-43ec-8ef8-fed12b53eb90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15674932</td>\n",
              "      <td>Okwudilichukwu</td>\n",
              "      <td>668</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15749177</td>\n",
              "      <td>Okwudiliolisa</td>\n",
              "      <td>627</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15694510</td>\n",
              "      <td>Hsueh</td>\n",
              "      <td>678</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>40.00</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15741417</td>\n",
              "      <td>Kao</td>\n",
              "      <td>581</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>34.00</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15766172</td>\n",
              "      <td>Chiemenam</td>\n",
              "      <td>716</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f145adb7-4c75-43ec-8ef8-fed12b53eb90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f145adb7-4c75-43ec-8ef8-fed12b53eb90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f145adb7-4c75-43ec-8ef8-fed12b53eb90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9bfc5708-6d99-433c-9916-5942830d26d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9bfc5708-6d99-433c-9916-5942830d26d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9bfc5708-6d99-433c-9916-5942830d26d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/test.csv', index_col='id').astype({'IsActiveMember' : np.uint8, 'HasCrCard' : np.uint8})\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ZTw4xbq2RSC5",
        "outputId": "19ca80fe-c378-4a3e-8abf-f122ff4cea0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CustomerId    Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
              "id                                                                           \n",
              "165034    15773898   Lucchese          586    France  Female 23.00       2   \n",
              "165035    15782418       Nott          683    France  Female 46.00       2   \n",
              "165036    15807120         K?          656    France  Female 34.00       7   \n",
              "165037    15808905  O'Donnell          681    France    Male 36.00       8   \n",
              "165038    15607314    Higgins          752   Germany    Male 38.00      10   \n",
              "\n",
              "         Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
              "id                                                                           \n",
              "165034      0.00              2          0               1        160976.75  \n",
              "165035      0.00              1          1               0         72549.27  \n",
              "165036      0.00              2          1               0        138882.09  \n",
              "165037      0.00              1          1               0        113931.57  \n",
              "165038 121263.62              1          1               0        139431.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-410df612-8747-42f8-b472-8c831828d181\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>165034</th>\n",
              "      <td>15773898</td>\n",
              "      <td>Lucchese</td>\n",
              "      <td>586</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>23.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>160976.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165035</th>\n",
              "      <td>15782418</td>\n",
              "      <td>Nott</td>\n",
              "      <td>683</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>46.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>72549.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165036</th>\n",
              "      <td>15807120</td>\n",
              "      <td>K?</td>\n",
              "      <td>656</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>34.00</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>138882.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165037</th>\n",
              "      <td>15808905</td>\n",
              "      <td>O'Donnell</td>\n",
              "      <td>681</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>36.00</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165038</th>\n",
              "      <td>15607314</td>\n",
              "      <td>Higgins</td>\n",
              "      <td>752</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>38.00</td>\n",
              "      <td>10</td>\n",
              "      <td>121263.62</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>139431.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-410df612-8747-42f8-b472-8c831828d181')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-410df612-8747-42f8-b472-8c831828d181 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-410df612-8747-42f8-b472-8c831828d181');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-287b4a88-833e-4544-a89b-c2b5f29d0e5c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-287b4a88-833e-4544-a89b-c2b5f29d0e5c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-287b4a88-833e-4544-a89b-c2b5f29d0e5c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "V_IaQddASBMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTWWb-KLR2mB",
        "outputId": "6da460f6-44dc-4f9b-f73b-69d182a64d12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 165034 entries, 0 to 165033\n",
            "Data columns (total 13 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   CustomerId       165034 non-null  int64  \n",
            " 1   Surname          165034 non-null  object \n",
            " 2   CreditScore      165034 non-null  int64  \n",
            " 3   Geography        165034 non-null  object \n",
            " 4   Gender           165034 non-null  object \n",
            " 5   Age              165034 non-null  float64\n",
            " 6   Tenure           165034 non-null  int64  \n",
            " 7   Balance          165034 non-null  float64\n",
            " 8   NumOfProducts    165034 non-null  int64  \n",
            " 9   HasCrCard        165034 non-null  uint8  \n",
            " 10  IsActiveMember   165034 non-null  uint8  \n",
            " 11  EstimatedSalary  165034 non-null  float64\n",
            " 12  Exited           165034 non-null  int64  \n",
            "dtypes: float64(3), int64(5), object(3), uint8(2)\n",
            "memory usage: 15.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "x7kQ_IlJSEzZ",
        "outputId": "ad35ab77-4aa9-43b9-81e2-43d479533f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    count        mean      std         min         25%  \\\n",
              "CustomerId      165034.00 15692005.02 71397.82 15565701.00 15633141.00   \n",
              "CreditScore     165034.00      656.45    80.10      350.00      597.00   \n",
              "Age             165034.00       38.13     8.87       18.00       32.00   \n",
              "Tenure          165034.00        5.02     2.81        0.00        3.00   \n",
              "Balance         165034.00    55478.09 62817.66        0.00        0.00   \n",
              "NumOfProducts   165034.00        1.55     0.55        1.00        1.00   \n",
              "HasCrCard       165034.00        0.75     0.43        0.00        1.00   \n",
              "IsActiveMember  165034.00        0.50     0.50        0.00        0.00   \n",
              "EstimatedSalary 165034.00   112574.82 50292.87       11.58    74637.57   \n",
              "Exited          165034.00        0.21     0.41        0.00        0.00   \n",
              "\n",
              "                        50%         75%         max  \n",
              "CustomerId      15690169.00 15756824.00 15815690.00  \n",
              "CreditScore          659.00      710.00      850.00  \n",
              "Age                   37.00       42.00       92.00  \n",
              "Tenure                 5.00        7.00       10.00  \n",
              "Balance                0.00   119939.52   250898.09  \n",
              "NumOfProducts          2.00        2.00        4.00  \n",
              "HasCrCard              1.00        1.00        1.00  \n",
              "IsActiveMember         0.00        1.00        1.00  \n",
              "EstimatedSalary   117948.00   155152.47   199992.48  \n",
              "Exited                 0.00        0.00        1.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd8eb85b-d41a-4f84-9114-8ff50e7a6d12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CustomerId</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>15692005.02</td>\n",
              "      <td>71397.82</td>\n",
              "      <td>15565701.00</td>\n",
              "      <td>15633141.00</td>\n",
              "      <td>15690169.00</td>\n",
              "      <td>15756824.00</td>\n",
              "      <td>15815690.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CreditScore</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>656.45</td>\n",
              "      <td>80.10</td>\n",
              "      <td>350.00</td>\n",
              "      <td>597.00</td>\n",
              "      <td>659.00</td>\n",
              "      <td>710.00</td>\n",
              "      <td>850.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>38.13</td>\n",
              "      <td>8.87</td>\n",
              "      <td>18.00</td>\n",
              "      <td>32.00</td>\n",
              "      <td>37.00</td>\n",
              "      <td>42.00</td>\n",
              "      <td>92.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>5.02</td>\n",
              "      <td>2.81</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.00</td>\n",
              "      <td>5.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>10.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balance</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>55478.09</td>\n",
              "      <td>62817.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>119939.52</td>\n",
              "      <td>250898.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumOfProducts</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>1.55</td>\n",
              "      <td>0.55</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HasCrCard</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsActiveMember</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>112574.82</td>\n",
              "      <td>50292.87</td>\n",
              "      <td>11.58</td>\n",
              "      <td>74637.57</td>\n",
              "      <td>117948.00</td>\n",
              "      <td>155152.47</td>\n",
              "      <td>199992.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exited</th>\n",
              "      <td>165034.00</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd8eb85b-d41a-4f84-9114-8ff50e7a6d12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd8eb85b-d41a-4f84-9114-8ff50e7a6d12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd8eb85b-d41a-4f84-9114-8ff50e7a6d12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0d7606a-38c3-4e84-b5ad-bf719de14c13\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0d7606a-38c3-4e84-b5ad-bf719de14c13')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0d7606a-38c3-4e84-b5ad-bf719de14c13 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Personalizing description of data\n",
        "\n",
        "desc = pd.DataFrame(index = list(train_df))\n",
        "desc['type'] = train_df.dtypes\n",
        "desc['count'] = train_df.count()\n",
        "desc['nunique'] = train_df.nunique()\n",
        "desc['%unique'] = desc['nunique'] / len(train_df) * 100\n",
        "desc['null'] = train_df.isnull().sum()\n",
        "desc['%null'] = desc['null'] / len(train_df) * 100\n",
        "desc['min'] = train_df.min()\n",
        "desc['max'] = train_df.max()\n",
        "desc\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "FR78hsqDOa_A",
        "outputId": "1edd03e4-3aac-4914-abf7-eee06a22c404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    type   count  nunique  %unique  null  %null       min  \\\n",
              "CustomerId         int64  165034    23221    14.07     0   0.00  15565701   \n",
              "Surname           object  165034     2797     1.69     0   0.00     Abazu   \n",
              "CreditScore        int64  165034      457     0.28     0   0.00       350   \n",
              "Geography         object  165034        3     0.00     0   0.00    France   \n",
              "Gender            object  165034        2     0.00     0   0.00    Female   \n",
              "Age              float64  165034       71     0.04     0   0.00     18.00   \n",
              "Tenure             int64  165034       11     0.01     0   0.00         0   \n",
              "Balance          float64  165034    30075    18.22     0   0.00      0.00   \n",
              "NumOfProducts      int64  165034        4     0.00     0   0.00         1   \n",
              "HasCrCard          uint8  165034        2     0.00     0   0.00         0   \n",
              "IsActiveMember     uint8  165034        2     0.00     0   0.00         0   \n",
              "EstimatedSalary  float64  165034    55298    33.51     0   0.00     11.58   \n",
              "Exited             int64  165034        2     0.00     0   0.00         0   \n",
              "\n",
              "                      max  \n",
              "CustomerId       15815690  \n",
              "Surname            Zuyeva  \n",
              "CreditScore           850  \n",
              "Geography           Spain  \n",
              "Gender               Male  \n",
              "Age                 92.00  \n",
              "Tenure                 10  \n",
              "Balance         250898.09  \n",
              "NumOfProducts           4  \n",
              "HasCrCard               1  \n",
              "IsActiveMember          1  \n",
              "EstimatedSalary 199992.48  \n",
              "Exited                  1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1bcd979-5bde-4799-87d9-7ff924da669d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>count</th>\n",
              "      <th>nunique</th>\n",
              "      <th>%unique</th>\n",
              "      <th>null</th>\n",
              "      <th>%null</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CustomerId</th>\n",
              "      <td>int64</td>\n",
              "      <td>165034</td>\n",
              "      <td>23221</td>\n",
              "      <td>14.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>15565701</td>\n",
              "      <td>15815690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Surname</th>\n",
              "      <td>object</td>\n",
              "      <td>165034</td>\n",
              "      <td>2797</td>\n",
              "      <td>1.69</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Abazu</td>\n",
              "      <td>Zuyeva</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CreditScore</th>\n",
              "      <td>int64</td>\n",
              "      <td>165034</td>\n",
              "      <td>457</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>350</td>\n",
              "      <td>850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Geography</th>\n",
              "      <td>object</td>\n",
              "      <td>165034</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>France</td>\n",
              "      <td>Spain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender</th>\n",
              "      <td>object</td>\n",
              "      <td>165034</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>Female</td>\n",
              "      <td>Male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>float64</td>\n",
              "      <td>165034</td>\n",
              "      <td>71</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>18.00</td>\n",
              "      <td>92.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tenure</th>\n",
              "      <td>int64</td>\n",
              "      <td>165034</td>\n",
              "      <td>11</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Balance</th>\n",
              "      <td>float64</td>\n",
              "      <td>165034</td>\n",
              "      <td>30075</td>\n",
              "      <td>18.22</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>250898.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NumOfProducts</th>\n",
              "      <td>int64</td>\n",
              "      <td>165034</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HasCrCard</th>\n",
              "      <td>uint8</td>\n",
              "      <td>165034</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IsActiveMember</th>\n",
              "      <td>uint8</td>\n",
              "      <td>165034</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <td>float64</td>\n",
              "      <td>165034</td>\n",
              "      <td>55298</td>\n",
              "      <td>33.51</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>11.58</td>\n",
              "      <td>199992.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exited</th>\n",
              "      <td>int64</td>\n",
              "      <td>165034</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1bcd979-5bde-4799-87d9-7ff924da669d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1bcd979-5bde-4799-87d9-7ff924da669d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1bcd979-5bde-4799-87d9-7ff924da669d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a20f8c7-24fc-480b-94a4-1827de6ea927\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a20f8c7-24fc-480b-94a4-1827de6ea927')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a20f8c7-24fc-480b-94a4-1827de6ea927 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c1dbeaa3-c3bc-4968-b260-f54631759b93\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('desc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c1dbeaa3-c3bc-4968-b260-f54631759b93 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('desc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = list(test_df._get_numeric_data())\n",
        "categorical_features = list(test_df.drop(numerical_features, axis = 1))"
      ],
      "metadata": {
        "id": "tIwjDL4JP7NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA"
      ],
      "metadata": {
        "id": "w4iG-CUNVIWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Exited'].value_counts().plot.pie(autopct ='%.1f%%', colors =['r', 'g'], labels = ['Stay', 'Churn'])\n",
        "plt.title('Stay vs Churn')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "zqL2X58AU45Q",
        "outputId": "ea7c63f4-91b9-4199-95f6-5b11f15a9ba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAH4CAYAAABT1nTPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLhUlEQVR4nO3dd3xV9f3H8dddSUhCFgl7C4QNIlP2FpCpVHBvrdZRayvW1lH9VdRqtdJqlSU4UBQZMiyIKCDgVqYoK4DIChDIvOv3xyEBZGXce8+9576fj8d9SG5uzv3kmuR9v9vm9/v9iIiISMSzm12AiIiIBIZCXURExCIU6iIiIhahUBcREbEIhbqIiIhFKNRFREQsQqEuIiJiEQp1ERERi1Coi4iIWIRCXUSCrk+fPtx2221mlyFieU6zCxCJND/88AP//ve/Wbt2LQcOHCAlJYVGjRrRp08frrnmmpLHvfzyyzRq1Ih+/fqZWG1wHThwgEmTJvHxxx+zZ88ebDYbDRs2pF+/flx99dUkJSWZXaJIVFGoi5TB119/zbXXXkvNmjUZPXo0GRkZ7Nmzh++++45p06adEur//e9/GThwoGVD/fvvv+fWW28lLy+PYcOG0aJFCwDWrVvHq6++ypdffsnkyZNNrlIkuijURcrg5ZdfpnLlyrz77runtUIPHjxoUlWhl5OTw+9+9zscDgfvv/8+F1xwwSmf//3vf88777wT0pr8fj+FhYXExcWF9HlFwonG1EXKICsri0aNGp2xW7lKlSol/87MzCQvL4/333+fzMxMMjMzGTduHAC7d+/m0UcfZeDAgbRu3ZpOnTpx9913s2vXrpKv37lzJ5mZmUydOvW05/n666/JzMzkgw8+OGONBw4coHnz5kyYMOG0z23dupXMzExef/11ANxuNxMmTGDAgAG0atWKTp06MXbsWFauXHnO12HGjBns3buXcePGnRboAOnp6dxxxx2n3f/ll19y+eWX06pVK/r27cvs2bNP+fyLL75IZmbmaV83a9YsMjMzT3mNisfply9fzqhRo2jdujUzZsxgzZo1ZGZmsmDBAl566SV69OhBq1atuO6669ixY8c5vy+RSKdQFymDWrVqsX79ejZv3nzOxz399NPExMTQvn17nn76aZ5++mmuuOIKANauXcs333zDkCFD+Mtf/sKYMWNYvXo11157Lfn5+QDUqVOHdu3aMXfu3NOuPW/ePBISEujbt+8Znzs9PZ0OHTqwcOHC0z63YMECHA4Hl1xyCQATJkxgwoQJdOrUiYcffpjbb7+dmjVrsn79+nN+f0uXLiUuLo6BAwee83En27FjB/fccw9du3Zl3LhxJCcnM27cOH788cdSX+PXtm3bxh/+8Ae6du3KQw89RLNmzUo+9+qrr7J48WJuvPFGbrvtNr777jvuv//+cj+XSCRQ97tIGdx4443ccsstjBgxgtatW3PRRRfRpUsXOnXqhMvlKnnc8OHDefTRR6lTpw7Dhw8/5Rq9evUqCdVivXv35oorruDDDz9kxIgRAIwYMYKHH36YLVu2lLSG3W43CxcuZMCAAVSqVOmsdQ4ePJiHH36YzZs306RJk5L7Fy5cSIcOHUhPTwdg2bJl9OzZk8cff7xMr8PWrVupX78+MTExpf6abdu28cYbb9C+fXsABg0aRM+ePZk1axYPPPBAmZ6/2I4dO5g4cSLdu3cvuW/NmjUAFBYWMnv27JIak5KS+L//+7/TXhMRK1FLXaQMunbtyowZM+jTpw+bNm1i4sSJ3HTTTfTo0YOPPvqoVNc4eczX7XZz6NAh6tatS1JSEhs2bCj53KBBg4iNjWXevHkl961YsYJDhw4xbNiwcz5H//79cTqdLFiwoOS+zZs389NPPzF48OCS+5KSkvjxxx/Zvn17qWovduzYMRISEsr0NY0aNSoJdIC0tDQaNGjAzp07y3Sdk9WuXfuUQD/ZqFGjTnnTUfzcFXk+kXCnUBcpo9atWzNhwgQ+//xzZs6cyW233UZubi733HMPP/3003m/vqCggBdeeIGePXvSqlUrOnfuTJcuXcjJyeHo0aMlj0tKSqJ3796njJ3PmzePatWq0blz53M+R1paGp07dz6lC37BggU4nU769+9fct/dd9/N0aNHGThwIEOHDuWpp55i06ZN5/0eEhMTyc3NPe/jTlajRo3T7ktOTubIkSNlus7JateufdbP1axZ85SPi+dB5OTklPv5RMKdQl2knGJiYmjdujX33Xcfjz76KG63m0WLFp336x5//HFefvllBg0axPPPP8/kyZOZMmUKKSkp+P3+Ux47YsQIdu7cyddff82xY8dYunQpQ4YMwW4//6/ukCFD2L59Oxs3bgSMrvfOnTuTlpZW8pgOHTqwePFi/v73v9O4cWPeffddRo0axcyZM8957YYNG7J9+3aKiorOW0cxh8Nx3sfYbLYz3u/1es94/7lmup/tNfr1ayxiJQp1kQBo2bIlAPv27TvvY4vHzceNG8cll1xC165dueiii05ppRfr3r07aWlpzJs3jyVLlpCfn3/aGP3Z9OvXD5fLxYIFC9i4cSPbt29nyJAhpz0uJSWFyy67jOeee45ly5aRmZnJiy++eM5r9+7dm4KCAv73v/+VqpbSOltr+ueffw7o84hYlUJdpAxWr159xpbeJ598Ahgt2GLx8fFn7Oo9U4t1+vTpZ2yNOp1OhgwZwsKFC5k1axZNmjShadOmpao1KSmJbt26sXDhQubPn4/L5TptI5xDhw6d8nFCQgJ169Y9bwt8zJgxZGRkMH78eLZt23ba5w8ePMh//vOfUtV5srp16wLwxRdflNyXl5d32tI3ETkzzX4XKYMnnniC/Px8+vfvT8OGDXG73Xz99dcsXLiQWrVqMWrUqJLHtmjRglWrVjFlyhSqVq1K7dq1adOmDb169WLOnDkkJibSqFEjvv32Wz777DNSUlLO+JwjRoxg+vTprFmzpsxLsgYPHswf//hH3nzzTbp163ba+vohQ4bQsWNHWrRoQUpKCmvXruXDDz/k6quvPud1k5OT+fe//82tt97KiBEjTtlRbsOGDXzwwQdceOGFZaoVjImINWvW5KGHHmLr1q04HA7ee+89UlNT1VoXKQWFukgZ/OlPf2LRokV88sknvP3227jdbmrWrMmVV17Jb3/721NCc9y4cTz88MM8//zzFBQUMHLkSNq0acNDDz2E3W5n3rx5FBYW0q5dO6ZMmcLNN998xuds2bIljRs3ZsuWLeed9f5rffr0IS4ujtzc3FNmvRe75pprWLp0KStXrqSoqIiaNWty7733ctNNN5332m3atGHevHlMmjSJZcuWMWfOHOx2Ow0bNuTWW2897xuDM3G5XEyYMIHHHnuMF154gYyMDK677jqSkpJ48MEHy3w9kWhj82vWiEjYGzFiBMnJybz22mtmlyIiYUxj6iJhbu3atWzcuLFkUxoRkbNRS10kTG3evJn169czefJkDh06xEcffURsbKzZZYlIGFNLXSRMffjhhzz44IN4PB6ee+45BbqInJda6iIiIhahlrqIiIhFKNRFREQsQqEuIiJiEQp1ERERi1Coi4iIWIRCXURExCIU6iIiIhahUBcREbEIhbqIiIhFKNRFREQsQqEuIiJiEQp1ERERi1Coi4iIWIRCXURExCIU6iIiIhahUBcREbEIhbqIiIhFKNRFREQsQqEuIiJiEQp1ERERi1Coi4iIWIRCXURExCIU6iIiIhahUBcREbEIhbqIiIhFKNRFREQsQqEuIiJiEQp1ERERi1Coi4iIWIRCXURExCIU6iIiIhahUBcREbEIhbqIiIhFKNRFREQsQqEuIiJiEQp1ERERi1Coi4iIWIRCXURExCIU6iIiIhahUBcREbEIhbqIiIhFKNRFREQsQqEuIiJiEQp1ERERi1Coi4iIWIRCXURExCIU6iIiIhahUBcREbEIhbqIiIhFOM0uQEQCxOs1bgA2G9jt4HCc+/G5ucbN7zceW/w1NtuJj2NijNu5eDzg8xlfc67nFJGgUqiLRAqfzwjPXwfngQOwZQts3QqHD0NOzplvR46c+nF+fumf22aDuDioVOnELT4eqlSBGjWgZs0Ttzp1oHZtqFrV+JqTFYe/02m8YRCRgLL5/X6/2UWIyHFerxF6LteJ+woKYMcO2Lz5RHgX37ZvL1s4h1py8umhX6MGNG4MF15ofAwn3rCcr0dARM5JoS5iFr8f3O4TQbZ/P3z2GXz99anhvXevuXUGU3IytGoFrVsbt3btoGVLoycAjNfnfMMIIlJCoS4SKkVFRgvcZjNa119+CatWwZo18PnnsGuX2RWGB5sNGjQ4EfRt2hhhX7euEfBut9F9b7OZXalI2FGoiwRD8YQ1h8P496ZNsHLliQDfsMHocpbSi4+HDh2gb18YMADatzdeX7f71OEKkSimUBcJlOJwKSqCTz6B//0PVq82utPz8syuznoSE6FHDyPkBw6EFi2M+xXyEsUU6iLl5fWeWDq2ZQvMmweLFsGnn4b35DWrSk+H3r2hTx+45BKoX9+Yt+DxKOQlaijURcqiuBXodsPSpTBnDixcaMxCl/BSp44R8P36wdChxqQ8teLF4hTqIudTHARHj8LcuUaQL1pkfCyRwek0WvGjRxu3lBQFvFiSQl3kTDweIwhycuD11+G994xudY/H7MqkopxO6NULLr8cfvMbSE1VwItlKNRFivn9xji53Q4ffQSTJsHs2VBYaHZlEixOp9E9f801MGqUsQNe8Rs6kQikUBcpbqXt2AETJ8Jrr8HOnWZXJaGWmAgjRsC11xoz6v1+4w2e1sNLBFGoS3QqnrleVARvvw1Tphjd6/p1EIDq1Y3W+z33QK1aar1LxFCoS3Qp/uP8+efwyivwzjua8CZn53DA8OFw333QtavG3iXsKdTF+vx+Y/e2/Hx46SVjrPyHH8yuSiLNhRfCvffC2LHaj17ClkJdrKt4G9bsbHjmGXj5ZWM2u0hFVK0Kt98Od91lbHjj9SrgJWwo1MV6iv/I7twJf/87TJ1qHF8qEkgxMcaSuPvvNw6dUde8hAGFulhH8Xj5pk3wxBMwY8aJg1VEgqlrV6NrftQo42dO4S4mUahL5Dt58tsTT8AHH2gWu5ijYUP429+McXeFu5jAbnYBIuXmdhv//fhjY4ewTp2MQ1UU6GKWrVvh6quhbVvjlD7QLoQSUgp1iTzFfyTnz4eLLjLO1v7kE3NrEjnZ2rVw6aVGt/znnxv3aShIQkDd7xI5fD5jKdG33xozj1esMLsikdIZNMhYgdGihWbLS1CppS6RweuFgwfhhhugXTsFukSWhQuhVStjrH3XrhN7J4gEmFrqEt7cbuMP4DPPwPjxcOyY2RWJVIzLBTfdZEyoq1LF6H0SCRCFuoSn4hntM2fCn/4E27ebXZFIYMXHG8NIf/0rxMZqb3kJCIW6hBeNm0u0qVUL/vMfGDZM4+1SYer3kfChcXOJRrt3G4fGjBxp/PxrCZxUgEJdzOfxGGPnTz1lbN4xdarWmkv0mT0bGjc2Tg/0+RTuUi7qfhdz+XxGV/t118G6dWZXIxIeunSByZOhSRNNpJMy0U+LmMPthqIiePBB6NhRgS5yslWroHVrePhh43elePdEkfNQS11Cz++HL74wWuebNpldjUh4a9IEJk6E7t2N3x2bzeyKJIyppS6h43ZDYSH84Q9G96ICXeT8Nm+GHj3gxhshJ0dj7XJOaqlLaPh8Rhf7mDGwcaPZ1YhEpqpVYdIkY195kTNQS12Cy+MxAn38eGjfXoEuUhH79sHQofC73xlzUtRql19RS12Cx+OBPXuM/a5XrjS7GhFrad0a3n3XWAaqDWvkOLXUJfCK3ye+8YZxKpUCXSTwvv/eOLd9yhTjYx0QI6ilLoHm8Rihfued8OqrZlcjEh1GjzbCPSbGODBGopZCXQLH7YZDh4wtL1evNrsakejSqBHMmQOZmeqOj2LqfpfA8Hrhq6+gTRsFuogZfvrJmIz6+uvGx2qvRSWFulRM8R+OV1811tL+8ou59YhEs/x8uP56uPlmo+dMs+OjjrrfpfyKx89/+1tj7ayIhI+2bY3u+Jo1dVZ7FFGoS/m43ZCdbYyfr1ljdjUicibp6TB/Plx0kcbZo4S636XsfD748ktj/FyBLhK+DhyAnj1h3jwteYsSCnUpveJOnf/+1/hDsXevufWIyPkVFMBll8G//mV2JRIC6n6X0vH5jNtttxnnPItI5LnnHnjuOePfOqfdkhTqcn5erzEpbtQoWLDA7GpEpCJGjYI33zQmz2mc3XIU6nJuHo9xXOqgQbB8udnViEggdOliTKBLTNQOdBajUJez83iM85v794evvza7GhEJpEaNYPFiqFVLwW4hGlSRM3O7Yf9+uPhiBbqIFf30E3TsCN9+awyxiSUo1OV0bjfs2gWdO8MPP5hdjYgEy/79xkqW+fO15M0iFOpyKo/HCPLOnSEry+xqRCTY8vNh5EiYOlXBbgEKdTnB4zE2lenWDfbtM7saEQkVnw9uuQXeeEPBHuEU6mLweuHjj6FvXzhyxOxqRCTUfD7jMJh33lGwRzCF+jlkZ2fzyCOP0KtXL1q2bEnXrl256aab+OqrrwDIzMxkyZIlJlcZAD4fvP8+DBkCeXlmVyMiZvH54OqrYfZsTZ6LUDq65xzuuusu3G4348ePp06dOhw8eJBVq1Zx+PBhs0sLHJ8P3noLrr1W785FxAjzK66A994z3uhrg5qIonXqZ5GTk0OHDh2YPn06HTt2PO3zffr0Yffu3SUf16pVi6VLl5KVlcWTTz7Jd999R35+Pg0bNuQPf/gDF198MQATJkxg0aJFfPDBB6dcb/jw4fTu3Zt77703qN/XKTwe+N//jJPWdO6yiJwsJsZosQ8YoGCPIOp+P4v4+Hji4+NZsmQJRUVFp33+3XffBeDJJ59kxYoVJR/n5eXRs2dPpk6dyvvvv0/37t25/fbb+fnnnwG4/PLL2bJlC99//33JtTZs2MAPP/zAZZddFoLv7DiPB774Ai6/XIEuIqcrKjJmxX/8sbriI4hC/SycTifjx49n9uzZtG/fnjFjxvDcc8+xadMmANLS0gBISkoiIyOj5OOmTZsyZswYmjRpQv369bn33nupW7cuS5cuBaB69ep069aNWbNmlTzXrFmz6NChA3Xq1AnNN+d2w48/wuDBxnIWEZEzKSyEYcNgxQq9+Y8QCvVzGDhwIMuXL+ell16ie/fufP7554waNeqUQP613NxcnnrqKQYNGkT79u258MIL2bJlS0lLHeA3v/kN8+fPp7CwkKKiIubNmxe6VrrbDb/8Ysxyt9LcABEJjvx8owGwZo2CPQIo1M8jNjaWrl27cueddzJjxgxGjhzJiy++eNbHP/XUUyxevJj77ruPN954g9mzZ9OkSRPcbnfJY3r37k1MTAyLFy/m448/xuPxcMkllwT/myney71PH9izJ/jPJyLWkJcHl1wCX32lYA9zmv1eRo0aNSpZxuZyufD+aqzpm2++YeTIkfTv3x8wWu4nT6gDo2t/xIgRzJo1C5fLxZAhQ4iLiwtu4V6v0ZXWr5+x57OISFkcO2ZMmluxApo21SEwYUqhfhaHDh3innvu4bLLLiMzM5OEhATWrVvHxIkT6du3L2DMeF+1ahXt2rUjJiaG5ORk6tWrx+LFi+nTpw82m43nn38e3xmWio0ePZrBgwcD8NZbbwX3m/H5jFAfMsQ4vEFEpDxycoyu+G++gZQU40x2CSv6P3IWCQkJtGnThtdee42srCw8Hg/Vq1dn9OjR3H777QA88MADjB8/npkzZ1KtWjWWLl3KuHHj+POf/8yYMWNITU3llltuITc397Tr169fnwsvvJAjR47Qpk2b4H0jxSsWr7gCPvkkeM8jItFh1y6jgbB8udFgsGsUN5xonbpJ/H4/AwYM4Morr+SGG24I7pPdfDNMmhTc5xCR6DJmjLFxlYQVvcUyQXZ2Nq+//joHDhxg1KhRwX2yBx9UoItI4M2YAY89ZnYV8itqqZsgMzOT1NRUHnroIYYOHRqcJ/F6Yfp0CHYvgIhEL5sN3n4bRo3SrnNhQqFuRW43fPedcYRqYaHZ1YiIlVWqBJ99Bi1aaEZ8GFCoW43XC4cOQZs2cNKGNyIiQVOzJnz9NVSpohnxJtOYupX4/cZs1OHDFegiEjo//2wsdfN4dNqjyRTqVmKzwZ13Gl1hIiKh9PXXxlnsWuJmKr36VuH1wquvGjcRETO89x785S9mVxHVNKZuBW43bNwIHTtqYpyImO+dd4xjWzW+HnIK9Ujn80FuLrRtC1u3ml2NiAgkJcG6dVCjhoI9xNT9HunsdrjmGgW6iISPnBy4/HKzq4hKCvVI5vPBP/4Bc+aYXYmIyKk+/xz+/Gezq4g66n6PVG43fPkl9Oih841FJDzZbPDhh9CrlzamCRGFeiTy+yEvD5o1g507za5GROTsqlaF9eshNVVbyYaAut8jkc0G99yjQBeR8Ldvn7F+XYEeEmqpRxq32zgXvX9/sysRESm9//wHbr1V4R5kCvVIom53EYlU8fGwdi3UratlbkGk7vdIYrPBvfcq0EUk8uTlwdixxt8xCRqFeqRwu2HpUpg40exKRETK5/PP4YkndOhLEKn7PRIUd7s3bw5ZWWZXIyJSfk4nrFkDrVppmVsQqKUeCWw2+P3vFegiEvk8Hrj+ep3mFiR6VcNdcbe7Tl8TEatYuxZefNE4XVICSt3v4czvh/x8Y7a7WukiYiVJSbBlC6SlqdUeQHolw5m63UXEqnJyjNU8CvSAUks9XLndsHIl9O5tdiUiIsGzfDl06qRJcwGiUA9XHo8x2/3HH82uREQkeFq0gO++005zAaJ+j3Dk8RhbKirQRcTq1q+H55/XpLkAUUs93Pj9cOwYNGgABw+aXY2ISPBVrgw//QTp6RpjryC9euHG74fHHlOgi0j0OHrUOHlSgV5haqmHE68Xdu+Gxo2hqMjsakREQuuTT6BLF02aqwC9LQonDgf84Q8KdBGJTr/9rQ58qSCFerjweGD1anj3XbMrERExx4YN8M9/atJcBaj7PZx07mwcdCAiEq0SE40Nt1JTza4kIqmlHg7cbnj7bQW6iMixY/DUUzqetZzUUg8HRUXQpAns2GF2JSIi5lNrvdzUUjeb12uMISnQRUQMaq2Xm1rqZvL74dAhY6OZnByzqxERCR8JCbBzJ6SkaEZ8Gailbia/H/72NwW6iMiv5ebC+PHG30kpNbXUzXT4MNSqBXl5ZlciIhJ+1FovM7XUzeL1wgsvKNBFRM4mNxeefFKt9TJQS90sBQVQpw4cOGB2JSIi4Uut9TJRS90MHg9MnKhAFxE5H7XWy0QtdTP4fNCoEWzbZnYlIiLhLz7eaK2npqq1fh5qqYea2w0zZyrQRURKKy9PrfVSUkvdDO3awTffmF2FiEjkKG6tp6WZXUlYU0s9lDweWLpUgS4iUlZ5eTBhgvF3VM5KLfVQ698fliwxuwoRkchTu7axpbZd7dGzUaiHitdrnBXcurXZlYRUnwYN2O1ynXb/lYcP88i+fex3OHg6I4PP4uPJtdtpUFTE7dnZDDx27KzX9AIvVqnC3KQkDjgcVPV4GJmTwx3Z2RRPoZmUmsrE44dB3HLoEDceOlTy9d/FxfFY1aq8k5WFM5DfrIgE39y5MGgQOPXbeyZ6VULF4YC//93sKkLu3awsvCd9/GNsLDfUrs0lR48C8ED16uQ4HLz088+ker3Mq1yZe2vU4L2sLJoXFp7xmq+mpfFWSgpP/fILjQoLWRcXx4PVq1PZ5+Paw4fZFBPDv6pU4eXduwG4rVYtuubmkllUhAd4pGpV/rZ3r374RSLRf/4DQ4eaXUXYUh9GKPh8xgSPmTPNriTk0rxeMk66fZyQQN2iIjrm5wPwTaVKXH3oEK0LCqjjdnNHdjZJPh/rY2PPes1v4uLoe+wYvXJzqe3xcMmxY3TLzeX7uDgAtsbEkFlYSJf8fLrk55NZWMjWmBjAaMG3z8+n9VneMIhImPvwQ+PvqTqZz0ihHirPPWd0wUexImBuUhKX5eSUdJNfmJ/PwsqVOWy34wPmV65Moc1WEvpncmFBAavj49l2vFt/U0wMX1WqRI/cXAAyi4rYHhPDz04nu51OtsfE0KSoiCyXi1nJydyrTX9EIpffD//+t45lPQuNqYeC2w01asDBg2ZXYqoFiYncX6MGH2/dSrXjb3By7HZ+X6MGKxIScPr9xPl8vLBnD93OsSe+D3guPZ2Jqak4MMbYf3/gALedNG7+VnIyU4+PqV9/6BBjjxzh+lq1uPrwYTw2GxOqVMHp9/PQ/v10OMcbCBEJQxkZsHs3nGG+TrTTsGKwud0wZ07UBzrAe8nJ9MjNLQl0gBeqVCHHbmfqzp2ker0sSUzk3ho1eGPnTjKLis54nYWVKzOvcmWePT6mvjE2lierVqWq18vI48fYjj1yhLFHjpR8zftJSST4/bQtKOCS+vV5NyuLX5xOfl+jBku3bSNG721FIsf+/fDee3DZZQr2X1H3e7C5XMY+71Fut9PJZ/HxXH5S0Ga5XLyemsrf9+6lS34+TYuK+F12Ni0LCngjJeWs13o6PZ1bs7MZcvQomUVFjDh6lOsOHeK/Z9mUIttuZ0JaGn/dt4/v4uKo73ZT3+2mc34+HijpxheRCPLSSwr0M1CoB9uePbB4sdlVmG5WcjJVvF56HR/3Bsg/vofzr38IHcC52s0Fdju/3v3Z4fef9WuerFqV6w8fprrHg89m4+StK7w2Gz7tJS0SeT79FDZv1tj6ryjUg6n4NLYo/6HzAbOSkhiRk3PKeE/DoiLqFRXxcNWqfB8XR5bLxeTUVFbGx9PvpPC/rnZtXj+p5d772DFeTktjWUICu5xOFicmMiU1lX5nWNu+Mj6e7S4XVx0+DECrggK2xsTwSXw8bycnYwcanKWbX0TC3IQJZlcQdjRRLtgaNoz6w1tWxMdzU+3aLNq2jQZu9ymf2+5y8Wx6Ol9VqkSe3U5dt5sbs7MZcXwdOxgb2IzMyeGu4/MSjtlsvJCezpLERA4e33xmyNGj3HnwIDEnXbvAZmN4vXo8v2cPzU5awjYzKYnn09OJ8ft5ZN++U3oPRCSCpKQYvaHHl7OKQj14vF5YtQq6dze7EhER65o8Ga6+WuPrx6n7PVhsNpg2zewqRESsbdIkBfpJ1FIPFrcbqlWDk9ZOi4hIgNlsRhd8tWpmVxIW1FIPBo8HFi5UoIuIBJvfDzNmGA0pUagHhdMJ06ebXYWISHSYOVNd8Mep+z0Yjh0ztjEsKDC7EhER61MXfAm11APN7TbeNSrQRURCQ13wJRTqgeZywbx5ZlchIhJd1AUPqPs98DweSEuDkzZPERGRILPZjINeqlQxuxJTqaUeSD6fseGMAl1EJLT8fnj//ajvgleoB5LfDx98YHYVIiLRae7cqO+CV/d7oLVuDWvXml2FiEj0qVQJsrOjei94tdQD6ZdfFOgiImbJzzeOuvZ4zv9Yi1KoB4rbra53ERGzzZ4N9uiNtuj9zgPN5TK2hhUREfN88EFUh7rG1APF4zGWUuTkmF2JiEh027QJMjPNrsIU0ft2JpB8Pli9WoEuIhIOli6FoiKzqzCFQj0QfD6Np4uIhIsVKyAmxuwqTKFQDwSnU+PpIiLhYvlysyswjcbUA2HvXqhe3ewqRESk2M8/Q40aZlcRcmqpV5TbDYsWmV2FiIicbOnSqFyvrlCvKIcD1qwxuwoRETnZihVRubQt+r7jQLPb4csvza5CREROtnx5VIa6xtQryuOBxEQoLDS7EhERKWazweHDkJRkdiUhFX1vYwJt40YFuohIuPH7jda612t2JSGlUK8It9s4P11ERMLPp5+aXUHIKdQrwuHQeLqISLhavtz4Ox1FFOoVoUlyIiLh66uvom67WIV6RbjdsG6d2VWIiMiZFBUZDa8omg+uUK+ItWuNYBcRkfD03XdR9XdaoV5eRUXGyWwiIhK+Nm2KqnF1hXp5uVwaTxcRCXcKdSkVm02hLiIS7jZtMruCkNKOcuVVWAgJCVG3sYGISESx2SAvD+LizK4kJNRSL6+NGxXoIiLhzu+HLVvMriJkFOrl4fXC5s1mVyEiIqWxdm3UHMOqUC8Prxe2bze7ChERKY1Nm6JmrbpCvTycToW6iEik2LTJWLEUBRTq5WG3w44dZlchIiKlEUUz4BXq5aWWuohIZIiiOVAK9fJSS11EJDLk58Pu3WZXERIK9fI4fBhyc82uQkRESmv9+qiYLKdQLw+10kVEIsvGjVFxsItCvax8PvjpJ7OrEBGRsvjlF2N3OYtTqJeVx6NJciIikebAAWM5ssUp1MvK4VCoi4hEmgMHoqKlXuq3LdOmTSv1Ra+99tpyFRMRHA6NqYuIRJoDB8yuICRKHepTp0495eNDhw6Rn59PUlISADk5OVSqVIm0tDRrhzqopS4iEmkU6qdaunRpyb/nzZvHm2++yf/93//RsGFDALZu3cpf//pXrrjiisBXGW527jS7AhERKYsoCfVynafer18//vWvf9G8efNT7l+3bh133333KW8ALMfnMyZbRMF6RxERy3A4oKjI2Obbwsr13e3fvx/PGY6x8/l8HDx4sMJFhbW8PAW6iEik8Xrh6FGzqwi6coV6ly5deOSRR1i/fn3JfevWrePRRx+lS5cuASsuLEXBD4WIiCVlZ5tdQdCVq/s9OzubBx54gOXLl+M8vu7P6/XSrVs3xo8fT5UqVQJeaNjYtAmaNTO7ChERKas1a6BjR7OrCKpyrcRPS0vj1VdfZdu2bWzduhWAhg0b0qBBg4AWF5YOHza7AhERKY+9e43hUwuvV6/Q9jq1atXC7/dTt27dkha7pfn9UdF9IyJiSfv3G7uCulxmVxI05RpTz8/P589//jNt27bl0ksvZc+ePQA8/vjjvPLKKwEtMKx4vXDkiNlViIhIeRw4YPmJzuUK9WeffZZNmzYxbdo0YmNjS+7v0qULCxYsCFhxYcfv15GrIiKR6sAByy9pK1ef+UcffcQ///lP2rZte8r9jRs3JisrKxB1hSe/HwoKzK5CRETKIz/f0uPpUM6WenZ29hlnuOfn52Oz+AumUBcRiVBer0L9TFq2bMmyZctOu3/mzJmntd4tR6EuIhKZPB7Lh3q5ut9///vfc8stt/DTTz/h9XqZNm0aW7Zs4ZtvvmH69OmBrjF82GxG942IiEQetdTPrH379syZMwev10uTJk1YuXIlaWlpzJgxg5YtWwa6xvBhs6mlLiISqbxesysIunIvLq9bty5PPPFEIGsJf3Y7FBaaXYWIiJTHGc4ssZpyhXqzZs1YsWLFaZPlDh06xMUXX8zGjRsDUlzY8fuNk35ErOrjj6FpU7OrEAmOuDizKwi6coX62baLLyoqwmXhnXrw+aLih0KiVFoa/p49+eHgD2w+uNnsakQCrra/Nu1S2pldRlCVKdSnTZsGgM1mY+bMmcTHx5d8zufz8cUXX9CwYcPAVhhO/H6FulhXdjae3KN8+fOXXPP+NWZXIxJwV7e+mukjLTyZmzKG+tSpUwGjpT5jxgzsJ+3M43K5qF27No899lhACww7CnWxMNfGH+jbtK/ZZYgEhcNm/eHTMoX60qVLAbjmmmuYMGECycnJQSkqrCnUxcoWLqRGh4dpkNKAbYe3mV2NSEA57dY/eKxcS9qmT58enYEOCnWxtkmT8Pv99Kzf0+xKRALOYXecdU6YVZT6bcuTTz7JPffcQ3x8PE8++eQ5H/vggw9WuLCwZLNBpUpmVyESPFlZePKO0bNeT6Z+O9XsakQCyml34sePDetuQFPqUN+wYQOe42v8NmzYcNbHWXrvd7tdLXWxPNfmn+jXUOPqYj0O2/GWuoVjqtShfvL2r5beCvZcFOoSDT78kNrjxlEnqQ47c3aaXY1IwLgcLvxYu/u93Ke0nc0PP/xQ7mLCnrrfJRpMngygcXWxnNS4VHx+n9llBFW5Qn3o0KFnPKVt0qRJjB49uqI1hbeT1uaLWNKPP+LON8bVRawkIyHD0uPpUM5Qv/7667nrrrt45JFHKCgoYO/evVx33XVMnDiRZ599NtA1hhe11CUKuH7cSr+G/cwuQySgqsZXxWG39lr1coX6Lbfcwttvv81XX33FsGHDGDZsGDExMcydO5f+/fsHusbwolCXaLB4MfVT6lMjsYbZlYgETI3KNbDbyhV7EaPc313dunVp3Lgxu3fv5tixYwwePJiMjIxA1haeFOoSDaZMATSuLtZSPbG62SUEXblCvbiFvmPHDubOncujjz7K448/zr333suRI0cCXWN4SU01uwKR4Fu/nqKCXI2ri6VUqVTl/A+KcDZ/ObbXadmyJddffz333HNPyalsWVlZ/PGPf2TPnj18+umnAS80rMTF6Vx1sb516/ipeiyNJzQ2uxKRCnPZXRT9tcjsMoKuXC31yZMnc//9959yzGrdunV56623uOKKKwJWXNiqVcvsCkSCb+lSGlVpRNWEqmZXIlJh6fHpZpcQEmUK9VtuuYWjR4/SsWNHAF555RVycnJKPn/kyBHmz58f2ArDUe3aZlcgEnzH16v3qNfD5EJEKi5a3pyWKdRXrFhBUdGJ7ouXX375lDF0r9fLtm1RcLKTQl2iwbffUlSYp3F1sYSMhCiYyE0ZQ/3Xw+9WP+3mjDwehbpEjZjtO+nbQPvAS+RTS13OzOdTqEv0+PhjmmU0i4pZw2JtGfEZeH1es8sIujKFus1ms/YpbKXhdCrUJXpMnQpA93rdza1DpIKqJlTF67d+qJf6lDYwutvHjRtHTEwMAEVFRTz66KNUOr4hy8nj7ZZlt0ODBmZXIRIaa9ZQVJRPz3o9mb1pttnViJRbNOz7DmUM9ZEjR57y8bBhw057zIgRIypUUERQS12iSEzWbo2rS8SrGl8Vp71MkReRyrX5TNTz+YwNaNxusysRCb6JE/HdeANVnq7C4YLDZlcjUi7r71hP84zmZpcRdJooVx52O9TQQRcSJaZNw26z061uN7MrESkXh81Bo7RGZpcREgr18qpTx+wKRELj009xuwu0Xl0iVqO0RsQ4YswuIyQU6uWlcXWJIs6dP2tcXSJWi6otzC4hZBTq5eHxQKPo6MoRAbCtWEHraq2pHFPZ7FJEyqxFRgvc3uiYA6VQLw+bDdq2NbsKkdB5/XUcdgdd63Y1uxKRMmuR0SJq9lhRqJeHwwEdOphdhUjoLF6M21OocXWJSG2rt42K5WygUC+/evWgsroiJXo4d/9CnwZ9zC5DpEycdicNUxuaXUbIKNQronVrsysQCRnbZ5/RrkY74l3xZpciUmqN0xrjcrjMLiNkFOrl5fPBhReaXYVI6Lz5Jk67k4vrXGx2JSKlFk0z30GhXn5erybLSXT54APcniKNq0tEiaaZ76BQLz+XS5PlJOo4f9mrcXWJKC0yWmC3RU/URc93GgzNmhlHsYpECduq1XSo2YE4Z5zZpYiUStvqbXHYHWaXETIK9YpwuYxgF4kWM2bgcrjoXLuz2ZWInFeMI4YGqdF1VLZCvaI0ri7RZPZs3F6Nq0tkaFKlSdSsTy+mUK+IoiLNgJfo4vPh2HdA4+oSEdrXbE+0nS6uUK8IlwsuusjsKkRCyr7mczrV6hQ1p15J5Opdvzcen8fsMkJKoV4R2gNeotE77xDrjKVjrY5mVyJyTgMuGBBVG8+AQr3ikpKgSROzqxAJnZkz8Xjd9KjXw+xKRM6qUVojqidWN7uMkFOoV5TPB717m12FSOh4PNgPHKR3ff3cS/jqXb83Pr/P7DJCTqFeUT4f9NGkIYku9i++pGudrlE3s1gih0JdysfphH79jPF1kWjx7rtUclXiohqaKCrhqf8F/aPyTadCPRDS0qBFdB0aIFHurbfweD30rK/16hJ+mqU3Iz0+3ewyTKFQDwSvV13wEl2KirBlZ2tcXcJS7wbR2fUOCvXA8PsV6hJ1HF99Tfe63XHYomdfbYkMfer3UahLBRSPq+twF4kms2aREJNA2+ptza5EpIQNG/0a9ovK8XRQqAdOQgJ06WJ2FSKh88YbeH1ejatLWGlVrRXJcclml2EahXqguN0waJDZVYiETl4eHDqkcXUJK73r98br85pdhmkU6oHidMLQoWZXIRJSjm+/o0e9Htht+lMi4aFvg75ml2Aq/SYGis0GLVtCjRpmVyISOrNnkxSbRKuqrcyuRAS7zU6v+r1w2KN38qZCPZD8fhg40OwqREJn2jSNq0vY6FW/F5VjK5tdhqkU6oHk9cLgwWZXIRI6OTn4jxyhV71eZlciwpiWY3B73WaXYSqFeiA5nXDppRAfb3YlIiHj/H4tvRv0xoa2ShbzuOwuftP8N1F31OqvKdQDrVIlGDbM7CpEQmfuXFLiUmie0dzsSiSKDbhgQFQvZSumUA80jweuucbsKkRCZ+pUfH6fxtXFVGNbjo36rndQqAee0wkDBkCVKmZXIhIa2dn4cjSuLuap5KzEqGajor7rHRTqwWG3w29+Y3YVIiHjXLeBPg10/oGYY0iTIVRyVTK7jLCgUA8Gvx+uvdbsKkRC54MPqBJfhcwqmWZXIlHoqlZX4fF6zC4jLCjUg8HhgM6doX59sysRCY3JkzWuLqZIik1icOPBOB3ReYDLrynUg8XrhSuvNLsKkdDYtw/vsaP0rKdQl9AanjmcGEeM2WWEDZvf7/ebXYQl+f3w44+Qqe5IiRKrVrG3ZQOqP1vd7EoCInV9KpV3ViYmJwafw0dBRgH72+7HnXRihnXyT8lU3l6Z2OxYHB4HP13+E76Yc5/jXZrrZnyVQdK2JHxOHwfaHOBog6Mln0vMSiRpaxI/9/o58N90BFp09SL6NugbtUet/ppa6sFis0GTJtC2rdmViITGggVUS6zGBakXmF1JQMTvi+dwk8NkDchiV59d4IPaS2tj85zYZMfmsZFbI5fsFtkBu27CrgQq76jMrt67OND2ANU+r4a9wPhTbS+yk/5dOvs67AvsNxuhqlSqQr8G0Xt2+pko1IPJ7YarrjK7CpHQmDQJv4XG1Xf33k1OwxyKUoooSi1ib+e9uPJcxGXHlTzmcNPDHGpxiIL0goBdNyYnhryqeRRWKeRo/aP4XD5cucZSrfRv0znc+DCeBE0KA7is+WXYbNrJ8GQK9WByuYyNaOx6mSUK/Pwzntxjlh1Xt7uN32NvTGDP6v71dQtTConLjsNeZCc2Oxabx4a7spu4fXHEZcdxuMnhgD5/JLu61dVoBPlU6rMItmrVoGdP+PhjsysRCTrXps30a9LP7DICz2+Mc+dn5FOUUhTU6+bVzONo/aPUXVQXv8PP3i578Tl8VPuiGr90+YWUH1NI2ZyCN9bL3o57A1tPBGmQ0oCudbtit6nRdDK9GsHmdsMNN5hdhUhoLFpEzaSa1EuuZ3YlAVX1i6rEHollT9c9IbnuwdYH2T5sOzuG7OBYnWOkbUgjr3oefpuftPVp7Oy/kyMXHKH6KmtMSiyPuzvdjc9/7kmJ0UihHmwuF4wZA9Wj95dPosjEifj9fsuMq4MRvAk/J7Cz70488YEbyy7tdV1HXCRtS+JA6wPE74snv2o+3jgvR+sdJe5QHDZ39I0pJ8UmcetFt2qC3Bko1EPBZoM77zS7CpHg27EDT36uNcbV/UbwJu5KZFefXXgSAxToZbmuH6p9UY397fbjd/nBDzafEeIl//VHX6jfeOGNxDnjzv/AKKRQDwWnE373O+NYVhGLc/3wI/0aRv64etUvq1J5e2X2XLwHn8uHI9+BI99xypI2R76D2EOxuI4as9NjD8cSeygWe+GJP621P6pNyg8pZbpuseQtyXhjveTWzgWgIL2ASnsrEXcgjtRNqRQmF553XbzV2G127ut8Hzai781MaajvIlSSkoz94P/7X7MrEQmu//2Pug88QK3Ktdh9dLfZ1ZRbyo8pANT5qM4p9//S+RdyGuaUPKbKuhMnMtZZUue0x7iOuXAUOsp0XTDeMKStTyOrf1bJfQXpBRxqeohay2rhifOwt/PeCn6XkWdE0xHUSa5z/gdGKe0oFyo+H2zbBo0bG7vNiVhV48aweTNXzbqKN9e+aXY1YjGf3fgZHWp10Hj6Waj7PVTsdrjgAhg82OxKRILrxx9xW2VcXcJK+5rt6VKniwL9HBTqoeTxwB//aHYVIkHn+mmrJcbVJbzc1/k+3F73+R8YxRTqoeR0GhvRtGljdiUiwbVkCQ1TG1I9UUs5JTBqVa7F6BajcTlcZpcS1hTqoeZ2w333mV2FSHBNngxAj3o9TC5ErOLOjloWXBoK9VBzuWDsWKhRw+xKRIJn3TqKCvI0ri4BEe+K5472d2gsvRQU6mbQZjQSBWK2bte4ugTEtW2upXJsZbPLiAgKdTMUb0YTH292JSLBs3QpTao0IT0+3exKJILZsHF/l/vNLiNiKNTNUrky3Hyz2VWIBM+UKYDG1aViRjYbyQVpF+g0tlLSq2QWmw0efdQIdxEr+vprigrzNa4u5ea0O3mm/zN4fYE9w97KFOpmsdmMrWO1bl0sLGZ7Fn0b9DW7DIlQN7e7mQYpDXDYHed/sAAKdXM5HHD//TqWVaxr2TKaZTQjNS7V7EokwiS4Eni89+NmlxFxFOpmc7mMbngRK3rtNew2O93rdTe7Eokwf7j4D6TGpWKz6TS2slCom83pNCbMNWlidiUigbdqFUVFBRpXlzKpllCNcV3Hqdu9HBTq4cDng/Hjza5CJChisnZpXF3K5JGej2g72HJSqIcDlwtGjoTOnc2uRCTwPv2UVlVbkRSbZHYlEgEapzXm1otu1e5x5aRQDxceD/zjH2ZXIRJ406djt9vpVreb2ZVIBBjfbzw+v8/sMiKWQj1cOJ3QtStceqnZlYgE1rJluN2FGleX8+pUqxOjmo1S13sFKNTDiddrtNYdmhwi1uLc9bPG1eW8nh3wLB6vx+wyIppCPZw4HJCZCddea3YlIgFlW7mSttXbkhiTaHYpEqYubXIpXet2xenQWHpFKNTDjc8Hf/87VKpkdiUigfPGGzjsDi6uc7HZlUgYctgcPDvgWW0HGwAK9XBjt0NGBjz0kNmViATOokW4PRpXlzO78cIbaVKlidalB4DN7/f7zS5CzsDjgbZtYf16sysRCQj/jh18bt9D50lauikn1EiswabfbSIxJlEnsQWAXsFw5ffDxInGwS8iFmD77DPa1WhHJaeGluSE/176X+Jd8Qr0ANGrGK5cLmMzmltvNbsSkcCYMQOXw0WXOl3MrkTCxJiWYxiaOVQbzQSQQj2c+f3wzDM6xU2sYd483J4ijasLABnxGfxn8H+00UyAKdTDmc1mzIL/17/MrkSk4nw+nHv306dBH7MrkTDw78H/pnJsZXW7B5hezXDndMLo0TB8uNmViFSYbc0aOtbqSKwj1uxSxEQjm45kdIvR6nYPAoV6JPD5jElzqalmVyJSMW+/TYwjhk61O5ldiZgkrVIarwx9Rd3uQaJQjwR2O6SkwIsvml2JSMXMmoXH69a4ehR7fuDzpMSlqNs9SPSqRgqnE666CoYNM7sSkfLzeLDvP6Bx9Sg1uPFgrmlzjbrdg0ihHkm8XnXDS8Szf/4FnWt3xmXXSVzRJCk2iUnDJmkr2CBTqEcSh8MIdM2Gl0g2cyZxzjg61OpgdiUSQs8OeJb0+HRtBRtkCvVI43TC1VcbN5FI9M47eLwejatHkX4N+3Fzu5vV7R4CCvVI5PfDK69A8+ZmVyJSdkVF2A4epHf93mZXIiGQHJvMlOFT1O0eIgr1SGSzGS322bMhIcHsakTKzPHlV3Sr200ttyjw2ojXqJ5YXd3uIaJQj1QuFzRoAK++anYlImX33ntUclWiXY12ZlciQXRfl/sY3nS43ryFkEI9kjmdMHYs3H672ZWIlM2bb+LxaVzdyi6uczFP93va7DKijkI90vn9xmz4iy4yuxKR0isowJZ9SOPqFpUen857v3kPP36zS4k6CvVIZ7MZt/ffN3adE4kQjm++pXu97tpZzGLsNjtvjnqT9Ph0dbubQL9NVuB0Qo0aMG2a2ZWIlN7775MYk0jb6m3NrkQC6C89/kK/hv0U6CZRqFuF0wlDh8L995tdiUjpTJ+O1+fVuLqFDG0ylMd6PYbNZjO7lKilULea8eOhWzezqxA5v2PH4MhhetXvZXYlEgBN05vy1mVv6fQ1kynUrejddyEjw+wqRM7L8e339KrXExtq2UWy5Nhk5l85n1hHrOZImEyvvtU4HFClijFxLjbW7GpEzm3OHJLikmlVrZXZlUg52W12Zlw+g7rJdXE6NI5uNoW6FTmd0LkzvPGGcRa7SLh67TV8GlePaI/3fpwBFwzQxLgwob/4VuVwwMiR8M9/ml2JyNkdPowvJ0fj6hHqihZX8Ofufzalyz0zM5MlS5aE/HnDnd5aWZndDnffDTt3wj/+YXY1ImfkXLuO3u21CU2kGXDBAKaPnI7P7wtKqO/fv5+XX36ZZcuWsXfvXqpUqUKzZs247rrr6NKlS8CfzyoU6tHgmWdgzx6jO14k3MybR2r37jTPaM6G/RvMrkZKoXPtzsy+YjZ2mz0ogb5r1y7Gjh1LUlISf/rTn2jSpAkej4cVK1bw2GOPsWjRooA/J0BRURExMTFBuXaoqPs9Gvj9MHUq9OtndiUip5syBZ/fp3H1CNGqais+vPpDYhwxQTt57bHHjLXuM2fOZODAgTRo0IDGjRtzww038M4775Q87tChQ9x55520adOGAQMG8NFHH5V8btasWbRv3/6U6y5ZsoTMzMySj1988UWGDx/OzJkz6dOnD61btwaMrv2ZM2ee9drhTKEeDYq3kp0zB9q2NbsakVMdOIDvqMbVI0HD1IZ8dO1HxLvigxbohw8fZvny5Vx11VXEx8ef9vmkpKSSf0+YMIFBgwYxd+5cevTowf3338/hw4fL9HxZWVl8+OGHTJgwgdmzZwf02mZQqEcLhwNiYuB//4P69c2uRuQUznUb6NOgj9llyDnUSKzBx9d9TEpcSlBnumdlZeH3+2nYsOF5Hzty5EguvfRS6tWrx3333UdeXh7ff/99mZ7P7Xbz9NNP07x5c5o2bRrQa5tBoR5NnE7j0JclS4y17CLhYv580uPTaVKlidmVyBmkxqXy0bUfUSOxBi6HK6jP5feX/mS3k7vS4+PjSUxMJDs7u0zPV7NmTdLS0oJybTMo1KONywX16sGCBVCpktnViBgmT9a4ephKcCWw6OpFNK7SOOiBDlCvXj1sNhtbt24972NdrlPrsdls+HzGNrV2u/20Nwhut/u0a1Q6y9/Bc107nCnUo5HTaZy//s47Rre8iNl++QVf7jGFepiJccQwe8xs2tVoF7LNZVJSUujWrRtvvPEGeXl5p30+JyenVNdJTU0lNzf3lGts2rQpYHWGK4V6tHI4YPBgmDnTaL2LmMy5YRP9GvY1uww5zm6z89Zlb9G7fu+Q7xb3yCOP4PP5GD16NB9++CHbt29ny5YtTJs2jSuuuKJU12jTpg2VKlXiueeeIysri3nz5jFr1qwgV24+hXo0s9th2DCYOxfi4syuRqLdwoVUS6xOw9TzT5CS4Hvl0lcY0XRE0Ga5n0udOnWYNWsWnTp14qmnnuLSSy/lhhtuYNWqVTz66KOlukZKSgrPPPMMn376KUOHDmX+/PncddddwS08DNj8ZZmVINbk9cKKFTBkCOTmml2NRKu6dfFv385Nc29iyrdTzK4mqj3V7yn+1PVPZpch5aCWuhhd8V27GrPiT1oDKhJSWVl48jSubiYbNiYMmqBAj2AKdTE4ndC+PSxbBmdY3iESCq4ffqRfQ+18aAaX3cVbl7/Fbzv81uxSpAIU6nKC0wmtWsHy5VC1qtnVSDT68ENqJdWibnJdsyuJKokxiSy4agGXN7vclBPXJHD0f09O5XRC48awciXUqmV2NRJtJk0CUBd8CKXHp/PJ9Z/Qq34vUybFSWAp1OV0xRvUfPaZtpSV0NqyBXfeMXrWV6iHQt3kuqy+aTWtqrYK+bI1CQ6FupyZywU1ahjB3rix2dVIFHH9uIV+DTSuHmwtMlrw+c2fUze5bkh2ipPQUKjL2blckJFhBHurVmZXI9Fi8WLqpdSjZuWaZldiWRfXuZjPbvqMKvFVFOgWo1CXcys+BGb1ahg0yOxqJBpMngxoXD1YhjQewtJrl5LgSlCXuwUp1OX8nE5jx7kPPoAo2JFJTLZxI+6CXI2rB8G1ba5lzpg5uBwuTYqzKIW6lI7dbtz+9S946SUj6EWCxLVlu8bVA+z+i+/ntRGvYbfZtWzNwvR/Vsru1lth0SJITja7ErGqJUu4IO0CqiVUM7uSiBfriOW/l/6XZ/o/AxhHiIp1KdSl7Ox26NkTvvwSmjQxuxqxouPj6j3q9TC5kMhWP6U+q29ezU0X3mR2KRIiCnUpH6fTWMv+1Vdw6aVmVyNW8/33FBXmaVy9AgY3Hsy3t31Li4wWGj+PIgp1KT+XC+LjYd48+OtfQd16EkAx27I0rl4Odpudx3s/zvwr55MYk6gla1FGoS4VYz/+I/TYYzB7NlSubGo5YiEff0xmeiZVKlUxu5KIkRGfwZJrlvDn7n8GUAs9CinUJTBsNhg82OiOb9rU7GrECqYYZ6prXL10utTuwve//Z7u9bprdnsU0/95CRynExo0gG++gTvuMLsaiXRffEFRUb7G1Uvhnk738OkNn5Ien64NZaKcze/3+80uQizG7zda7v/7H1x3Hfzyi9kVSaTavJl1yYW0eknbFJ9J5ZjKTBo+idHNR5tdioQJtdQl8IonzPXpAxs2wMiR5tYjkeuTT2ie0ZyUuBSzKwk7LTJa8M1t3zCyqX6/5ASFugSP02lsUDNrFkydqkl0UnavGTugda/b3exKwsrN7W7mi1u+oF5KPXW3yykU6hJcxbPjr7oK1q+Hbt3MrUciy4oVuN0FGlc/7oLUC1h23TJeHfoqcc44BbqcRqEuoeF0Guezf/IJ/P3vxhp3kVJw7fyZvg36ml2GqRw2B/dffD/r71jPxXUuBrTdq5yZQl1Cx+k0Wu4PPGBsMdusmdkVSSRYvpxWVVuRFJtkdiWmaF2tNV/c8gVP93uaWGesNpORc1KoS+jZ7Uagf/ONcZSrWhxyLtOn47A76Fqnq9mVhFSsI5Yn+jzBV7d+RauqrdQyl1JRqIs5XC6IjTWOcl2zBtq3N7siCVcffYTbXRhV4+pd63Rl3R3reLDbgzjtTpwOjZ1L6SjUxXwXXmgE+8SJkJFhdjUShpy790TFuHrlmMpMGDyBFTeuoH5Kfe0MJ2WmnxgxX/FY+3XXwZYtRpe8Q3tWywm2lSu5sPqFJLgSzC4laAY1GsSm323i9otuB9DMdikXhbqED6cTEhPhhRdg7Vro1cvsiiRcvPkmDrujZOa3lVRPrM7rI19nwVULqJZQTYewSIUo1CW82GzGrXFj+PhjeOcdqFPH7KrEbAsW4PYUWWpcPSk2iSf6PMHWu7dyRcsrAJ2qJhWnvd8lvLnd4PXCE0/AP/4BhYVmVyQm8WdlsZpdXDw5slvrsY5Y7ux4J3/t8Vcqx1RWkEtAqaUu4c3lgrg4+Nvf4IcfYOhQsysSk9hWraJ9zfZUclYyu5RysdvsXN/2erbes5Vn+j9DcmyyAl0CTqEukcFuh9q1Ye5cY1e6ntbphpVSmjEDl8NF59qdza6kzIZlDmPDHRuYMnwK1ROqY7fZte5cgkKhLpGjeEb8xRfDsmWwciX0729qSRJCc+bg8bojaly9e93urL5pNXPGzKFRWiMA7Hb92ZXg0U+XRB7n8aU+HTsaZ7Z//jkMHmxuTRJ8Ph/2vfvoU7+P2ZWcV6uqrZh/5Xw+veFTLqp5EaBJcBIaCnWJXMXhfuGFMH8+fPstjBihbWctzL7mczrV7kSsI9bsUs6ofkp9po+czre3f0v/hkYvktabSygp1CXyFYd7ixbw/vuwbh2MHn3i2FexjrffJsYRQ8daHc2u5BTd63Zn1m9mseXuLYxpOQa7za6DV8QU+qsn1lEc7pmZxvr2jRvhyiu1O52VvPde2Iyrxzpiub7t9az97Vo+veFTLm1yKXabXS1zMZXWqYt1eb1GoG/bBs88A6+/DkePml2VVJBvzx4+yd9In2nmjK3XSKzBHR3u4M4Od5JaKRWvz6vxcgkbCnWxPp/P+G9BAUydCi+9ZHTRS2SaO5eCQf1JejIJt88dsqftVKsT93S6h9EtRgMaK5fwpO53sT673bjFx8Mttxj7yq9cCWPHQkyM2dVJWb37LnHOONrXDP5xvS67i7Etx/LlLV+y+ubVXN78cuMoVAW6hCm11CU6FXfNZ2fDlCnGbf16s6uS0oiJwZOXy1+X/ZXxK8YH5Sky4jO4rf1t3NXxLqomVFUXu0QMhbqIx2NMsvv6a3jlFZgxA44cMbsqOQffvr0syfmWga8PDNg1U+NSGdlsJGNajKFPA2O8XkEukUahLlLM6zXWuLvd8O67MG2acVKcO3TjtlJKCxaQ168nSU8m4fV7y32ZlLgUhmcOZ0zLMfRr2A+HzYHP71OYS8RSqIucidttHCZz7Jixsc3s2bBgAeTkmF2ZANx8M7z6Kh1f7cgXP39Rpi9Nik1iWOYwxrQYw4ALBuC0O/H6vRonF0tQqIucT3HAezzGnvPvv28cLLNrl9mVRa+4OLy5Rxn30YP847N/nPfhiTGJDG0ylLEtx3JJo0twOVx4fB4FuViOQl2kLIq76O12Y1va996DOXOMGfUSUt4D+/kw+3OGvDnkjJ9Pik3ikkaXMLblWAY3HkyMI0ZBLpanUBcpL5/PuDmdkJV1IuA/+0zj8KGweDHHenQmeXwyPr+POGccF9e5mL4N+jLwgoG0rd4Wh92hIJeoolAXCZTibvqiIvjyS1i+3Aj4Vatg/36zq7Oe3/0OXnyRf635F22qtaFLnS7EOGJwe9047U6dVy5RSaEuEgx+vzEG7zp+qMf27cZ4/GefGbcNG4zHSOmlpECXLtCtG/ToAR06UOS0YbfZS24i0U6hLhIqbrex4Y3dbuxBv2oVrFhhhPyaNcZMezHUqGGcute8ObRsCd27Q9OmxufcbmPIQy1xkdMo1EXMcvKYvM8HP/9snCy3aRP8+CNs3mz8d8cOY4KeFdWubQR38+ZGiLduDc2aQeXKxue9XuO1cekYU5HSUKiLhBO//0SLvvjIWLfbCPaNG+GHH04E/ubNxhuBcBYbCxkZUK0aVK9uHIt7cngnJBiPU3iLBIRCXSRS+HwntrS1Hx8/zs+HvXth3z7YswcOHDAm5RXfsrONDXN+fSvN7PzipXvFQwbF/46JMYK6alXjVq3aiX9XrQo1axoBnp4OiYmnXlPhLRJUCnURqyienOf3GwHsPMcyrsJCY5Z+cVjb7SdC3GY70UtQGsVvNuDUNxwiEnIKdREREYvQW2oRERGLUKiLiIhYhEJdRETEIhTqIiIiFqFQFxERsQiFuoiIiEUo1EVERCxCoS4iImIRCnURERGLUKiLiIhYhEJdRETEIhTqIiIiFqFQFxERsQiFuoiIiEUo1EVERCxCoS4iImIRCnURERGLUKiLiIhYhEJdRETEIhTqIiIiFqFQFxERsQiFuoiIiEUo1EVERCxCoS4iImIRCnURERGLUKiLiIhYhEJdRETEIhTqIiIiFqFQFxERsQiFuoiIiEUo1EVERCxCoS4iImIRCnURERGLUKiLiIhYhEJdRETEIhTqIiIiFqFQFxERsQiFuoiIiEUo1EVERCxCoS4iImIRCnURERGLUKiLiIhYhEJdRETEIhTqIiIiFqFQFxERsQiFuoiIiEUo1EVERCxCoS4iImIRCnURERGLUKiLiIhYhEJdRETEIhTqIiIiFqFQFxERsQiFuoiIiEUo1EVERCzi/wHwzxI3AOZUGQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## as visible, data is slightly imbalanced and will probably need to be treated"
      ],
      "metadata": {
        "id": "j1g_e1Y8VOug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(nrows =5, ncols =2,figsize=(15,27))\n",
        "axs = axs.flatten()\n",
        "\n",
        "ds= train_df.loc[:, 'CreditScore':'EstimatedSalary']\n",
        "\n",
        "for i, var in enumerate(ds.columns.tolist()):\n",
        "\n",
        "  sns.histplot(x =var, data =ds, ax =axs[i], color='blue')\n",
        "  #axs[i].set_title(var)\n",
        "  axs[i].tick_params(axis='x', rotation =0)\n",
        "\n",
        "\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ssGFeKtRWM7Y",
        "outputId": "d756638e-0d43-4548-bb84-258b626968f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x2700 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Boxplot\n",
        "\n",
        "ds.boxplot(vert=False, color= 'g')\n",
        "plt.xlabel('Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "id": "aVEll_U-WfhZ",
        "outputId": "e50cdf01-0dc6-4065-f0f4-5d6cb533e25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# there are outliers in some features. Balance and Age will be treated from right side of their distrubutions, CreditScore will be treated from left side of its distribution"
      ],
      "metadata": {
        "id": "GGMJPYqlcTdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['Gender', 'HasCrCard', 'IsActiveMember', 'Geography' ]\n",
        "\n",
        "fig, axs = plt.subplots(nrows =2, ncols =2)\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, col in enumerate(train_df[cols]):\n",
        "  ax = sns.countplot(data = train_df, x=col, ax=axs[i], hue = train_df[\"Exited\"])\n",
        "  for i in ax.containers: ax.bar_label(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "BwCVyFjjnWX5",
        "outputId": "4d97bbef-d9c2-412f-d72a-bf6cfed34da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Checking correlation between features\n",
        "sns.set_theme(style='white')\n",
        "\n",
        "corr =train_df.corr()\n",
        "\n",
        "mask = np.triu(np.ones_like(corr, dtype =bool))\n",
        "\n",
        "f,ax = plt.subplots(figsize=(15, 10))\n",
        "\n",
        "cmap =sns.diverging_palette(230,20, as_cmap =True)\n",
        "\n",
        "\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True, annot_kws={\"fontsize\":8})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "czAzziexnaTQ",
        "outputId": "9c18a1cb-c575-454a-bdec-c052ab760777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = train_df.corr()\n",
        "correlation['Exited'].sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkGGiHCyoClI",
        "outputId": "c5d020d1-047d-4dd6-f47a-84cf36e08ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumOfProducts     -0.21\n",
              "IsActiveMember    -0.21\n",
              "CreditScore       -0.03\n",
              "HasCrCard         -0.02\n",
              "Tenure            -0.02\n",
              "EstimatedSalary    0.02\n",
              "Balance            0.13\n",
              "Age                0.34\n",
              "Exited             1.00\n",
              "Name: Exited, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights based on EDA:\n",
        "- No missing values\n",
        "- Data is an imbalanced data\n",
        "- Some features has no value and should be dropped (like RowNumber, CustomerId,and Surname)\n",
        "- Correlations between features are quite low and acceptable\n",
        "- Age and Balance has high positive corrleation with Customer Churn\n",
        "- Active members are less likly to leave (negative corr)\n",
        "\n"
      ],
      "metadata": {
        "id": "N2sEcF5YpmDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparation"
      ],
      "metadata": {
        "id": "sEcsKSjyQHi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X =  train_df\n",
        "y = X.pop('Exited')\n",
        "\n"
      ],
      "metadata": {
        "id": "4CX6Je9KQKHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "mLuKUvPNUMak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nullify(x):\n",
        "    x_copy = x.copy()\n",
        "    x_copy['Balance'] = x_copy['Balance'].replace({0 : np.nan})\n",
        "    return x_copy\n",
        "\n",
        "Nullify = FunctionTransformer(nullify)"
      ],
      "metadata": {
        "id": "SVG1KIq7UVMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EstimatedSalary and Age as integer by multiplying them by 100 and 10 respectively"
      ],
      "metadata": {
        "id": "zfyvFhVYVGR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def salary_rounder(x):\n",
        "    x_copy = x.copy()\n",
        "    x_copy['EstimatedSalary'] = (x_copy['EstimatedSalary'] * 100).astype(np.uint64)\n",
        "    return x_copy\n",
        "\n",
        "SalaryRounder = FunctionTransformer(salary_rounder)"
      ],
      "metadata": {
        "id": "B6RxYJGkUVJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def age_rounder(x):\n",
        "    x_copy = x.copy()\n",
        "    x_copy['Age'] = (x_copy['Age'] * 10).astype(np.uint16)\n",
        "    return x_copy\n",
        "\n",
        "AgeRounder = FunctionTransformer(age_rounder)"
      ],
      "metadata": {
        "id": "TDI9UbiJUVF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_rounder(x):\n",
        "    x_copy = x.copy()\n",
        "    x_copy['Balance'] = (x_copy['Balance'] * 100).astype(np.uint64)\n",
        "    return x_copy\n",
        "\n",
        "BalanceRounder = FunctionTransformer(balance_rounder)"
      ],
      "metadata": {
        "id": "zdbxJaVdUVCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_generator(x):\n",
        "\n",
        "    x_copy = x.copy()\n",
        "    #x_copy['IsSenior'] = (x_copy['Age'] >= 600).astype(np.uint8)\n",
        "    x_copy['IsActive_by_CreditCard'] = x_copy['HasCrCard'] * x_copy['IsActiveMember']\n",
        "    x_copy['Products_Per_Tenure'] =  x_copy['Tenure'] / x_copy['NumOfProducts']\n",
        "    x_copy['ZeroBalance'] = (x_copy['Balance'] == 0).astype(np.uint8)\n",
        "    x_copy['AgeCat'] = np.round(x_copy.Age/20).astype(np.uint16)#.astype('category')\n",
        "    x_copy['AllCat'] = x_copy['Surname']+x_copy['Geography']+x_copy['Gender']+x_copy.EstimatedSalary.astype('str')+x_copy.CreditScore.astype('str')+x_copy.Age.astype('str')+x_copy.NumOfProducts.astype('str')+x_copy.Tenure.astype('str')+x_copy.CustomerId.astype('str')#+np.round(x_copy.IsActiveMember).astype('str')\n",
        "\n",
        "    return x_copy\n",
        "\n",
        "FeatureGenerator = FunctionTransformer(feature_generator)"
      ],
      "metadata": {
        "id": "seRSXT3NVpBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def svd_rounder(x):\n",
        "\n",
        "    x_copy = x.copy()\n",
        "    for col in [column for column in list(x) if 'SVD' in column]:\n",
        "        x_copy[col] = (x_copy[col] * 1e18).astype(np.int64)\n",
        "\n",
        "    return x_copy\n",
        "\n",
        "SVDRounder = FunctionTransformer(svd_rounder)"
      ],
      "metadata": {
        "id": "fE8l7ZxUVo-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureDropper(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, cols):\n",
        "        self.cols = cols\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, x):\n",
        "        return x.drop(self.cols, axis = 1)"
      ],
      "metadata": {
        "id": "0Tn1oHyyVo7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Categorizer(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, cols : list):\n",
        "        self.cols = cols\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, x):\n",
        "        return x.astype({cat : 'category' for cat in self.cols})"
      ],
      "metadata": {
        "id": "s1P7EFlqWDL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vectorizer(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, max_features = 1000, cols = ['Surname'], n_components = 3):\n",
        "        self.max_features = max_features\n",
        "        self.cols = cols\n",
        "        self.n_components = n_components\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        self.vectorizer_dict = {}\n",
        "        self.decomposer_dict = {}\n",
        "\n",
        "        for col in self.cols:\n",
        "            self.vectorizer_dict[col] = TfidfVectorizer(max_features = self.max_features).fit(x[col].astype(str), y)\n",
        "            self.decomposer_dict[col] = TruncatedSVD(random_state = seed, n_components = self.n_components).fit(\n",
        "                self.vectorizer_dict[col].transform(x[col].astype(str)), y\n",
        "            )\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, x):\n",
        "        vectorized = {}\n",
        "\n",
        "        for col in self.cols:\n",
        "            vectorized[col] = self.vectorizer_dict[col].transform(x[col].astype(str))\n",
        "            vectorized[col] = self.decomposer_dict[col].transform(vectorized[col])\n",
        "\n",
        "        vectorized_df = pd.concat([pd.DataFrame(vectorized[col]).rename({\n",
        "            f'truncatedsvd{i}' : f'{col}SVD{i}' for i in range(self.n_components)\n",
        "        }, axis = 1) for col in self.cols], axis = 1)\n",
        "\n",
        "        return pd.concat([x.reset_index(drop = True), vectorized_df], axis = 1)"
      ],
      "metadata": {
        "id": "ZSa8FvBoWDJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "sQOAWYXzqK4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shape of original dataset\n",
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc1hlcn40Amo",
        "outputId": "6f2c50b5-ed89-448e-b7cf-857de1697cd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(165034, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Treating outliers**"
      ],
      "metadata": {
        "id": "E6deKF3t--wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1st treating balance column\n",
        "upper_bound = np.percentile(train_df['Balance'], 95)\n",
        "train_df = train_df[train_df['Balance'] < upper_bound]\n",
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ok_v6CId3X",
        "outputId": "1e82133a-5aa9-4b38-df22-68ea0af4fff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156781, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2nd treatment is done on CreditScore column\n",
        "lower_bound =np.percentile(train_df['CreditScore'], 1)\n",
        "lower_bound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nm0Vh-_29Bg",
        "outputId": "b94f443c-e6cc-45ec-be05-14e94d75aa8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "468.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df[train_df['CreditScore'] > lower_bound]\n",
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvpxK4nU8zcI",
        "outputId": "c64bf3cd-c100-4f7e-b524-0b04c7741dae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(155133, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3rd treatment has been done on age column\n",
        "upper_bound = np.percentile(train_df['Age'], 98)\n",
        "upper_bound"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GGG6GfG9I-p",
        "outputId": "3d787a3a-ad8d-450f-cf02-a3658534a238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "62.0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df[train_df['Age'] < upper_bound]\n",
        "train_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaokF-MN_J-5",
        "outputId": "4f8ad84f-57cb-4530-d611-c473a5a74208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(151947, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.reset_index(drop=True, inplace=True)\n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "dt-ylWi-NU0l",
        "outputId": "4db92d58-067a-4974-9c65-c213ed2f5982"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CreditScore Geography  Gender   Age  Tenure   Balance  NumOfProducts  \\\n",
              "0               668    France    Male 33.00       3      0.00              2   \n",
              "1               627    France    Male 33.00       1      0.00              2   \n",
              "2               678    France    Male 40.00      10      0.00              2   \n",
              "3               581    France    Male 34.00       2 148882.54              1   \n",
              "4               716     Spain    Male 33.00       5      0.00              2   \n",
              "...             ...       ...     ...   ...     ...       ...            ...   \n",
              "151942          630    France    Male 50.00       8      0.00              2   \n",
              "151943          667     Spain  Female 33.00       2      0.00              1   \n",
              "151944          792    France    Male 35.00       3      0.00              1   \n",
              "151945          565    France    Male 31.00       5      0.00              1   \n",
              "151946          850    France    Male 31.00       1      0.00              1   \n",
              "\n",
              "        HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
              "0            1.00            0.00        181449.97       0  \n",
              "1            1.00            1.00         49503.50       0  \n",
              "2            1.00            0.00        184866.69       0  \n",
              "3            1.00            1.00         84560.88       0  \n",
              "4            1.00            1.00         15068.83       0  \n",
              "...           ...             ...              ...     ...  \n",
              "151942       1.00            1.00          5962.50       0  \n",
              "151943       1.00            1.00        131834.75       0  \n",
              "151944       0.00            0.00        131834.45       0  \n",
              "151945       1.00            1.00        127429.56       0  \n",
              "151946       1.00            0.00         61581.79       1  \n",
              "\n",
              "[151947 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0d4f0bf-a65c-4c3a-9e90-e568296448fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>668</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>627</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>678</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>40.00</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>581</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>34.00</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>716</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151942</th>\n",
              "      <td>630</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>50.00</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5962.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151943</th>\n",
              "      <td>667</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>33.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>131834.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151944</th>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>131834.45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151945</th>\n",
              "      <td>565</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>31.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>127429.56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151946</th>\n",
              "      <td>850</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>31.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>61581.79</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151947 rows  11 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0d4f0bf-a65c-4c3a-9e90-e568296448fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0d4f0bf-a65c-4c3a-9e90-e568296448fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0d4f0bf-a65c-4c3a-9e90-e568296448fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bcfa8dfe-86ff-4832-9df9-1a20f7a48fce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcfa8dfe-86ff-4832-9df9-1a20f7a48fce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bcfa8dfe-86ff-4832-9df9-1a20f7a48fce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5c410d40-2db3-4384-a442-70a188b239c9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5c410d40-2db3-4384-a442-70a188b239c9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoding Categorical varaibles using OrdinalEncorder()\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "one_enc=OneHotEncoder(sparse=False)\n",
        "\n",
        "result = one_enc.fit_transform(train_df[['Gender', 'Geography']])\n",
        "one_enc =pd.DataFrame(result)\n",
        "\n",
        "## bring back column names\n",
        "\n",
        "#ord_enc.columns=['Gender_enc', 'Geography_enc']\n",
        "one_enc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jTco6-e5zl7u",
        "outputId": "9164d1d2-0be3-4ff2-f3eb-b9c0904e4444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0    1    2    3    4\n",
              "0      0.00 1.00 1.00 0.00 0.00\n",
              "1      0.00 1.00 1.00 0.00 0.00\n",
              "2      0.00 1.00 1.00 0.00 0.00\n",
              "3      0.00 1.00 1.00 0.00 0.00\n",
              "4      0.00 1.00 0.00 0.00 1.00\n",
              "...     ...  ...  ...  ...  ...\n",
              "151942 0.00 1.00 1.00 0.00 0.00\n",
              "151943 1.00 0.00 0.00 0.00 1.00\n",
              "151944 0.00 1.00 1.00 0.00 0.00\n",
              "151945 0.00 1.00 1.00 0.00 0.00\n",
              "151946 0.00 1.00 1.00 0.00 0.00\n",
              "\n",
              "[151947 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77bfda89-724e-49aa-883b-04ff594769eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151942</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151943</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151944</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151945</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151946</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151947 rows  5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77bfda89-724e-49aa-883b-04ff594769eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77bfda89-724e-49aa-883b-04ff594769eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77bfda89-724e-49aa-883b-04ff594769eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-60aa248f-7e0f-4173-a4cd-a80e15b15aec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60aa248f-7e0f-4173-a4cd-a80e15b15aec')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-60aa248f-7e0f-4173-a4cd-a80e15b15aec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ce09ee2a-5504-4852-a08a-e1429320edd6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('one_enc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ce09ee2a-5504-4852-a08a-e1429320edd6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('one_enc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoding Categorical varaibles using OrdinalEncorder()\n",
        "\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "data = np.asarray(train_df[['Gender', 'Geography']])\n",
        "\n",
        "encoder=OrdinalEncoder()\n",
        "\n",
        "result = encoder.fit_transform(data)\n",
        "ord_enc =pd.DataFrame(result)\n",
        "\n",
        "## bring back column names\n",
        "\n",
        "ord_enc.columns=['Gender_enc', 'Geography_enc']\n",
        "ord_enc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NpR9MMrwLn-c",
        "outputId": "53704c50-6274-49c0-bfa6-4ecbf1843223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Gender_enc  Geography_enc\n",
              "0             1.00           0.00\n",
              "1             1.00           0.00\n",
              "2             1.00           0.00\n",
              "3             1.00           0.00\n",
              "4             1.00           2.00\n",
              "...            ...            ...\n",
              "151942        1.00           0.00\n",
              "151943        0.00           2.00\n",
              "151944        1.00           0.00\n",
              "151945        1.00           0.00\n",
              "151946        1.00           0.00\n",
              "\n",
              "[151947 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6e35216-65b9-48b2-8018-7f928e5c6adf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender_enc</th>\n",
              "      <th>Geography_enc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.00</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151942</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151943</th>\n",
              "      <td>0.00</td>\n",
              "      <td>2.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151944</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151945</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151946</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151947 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6e35216-65b9-48b2-8018-7f928e5c6adf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6e35216-65b9-48b2-8018-7f928e5c6adf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6e35216-65b9-48b2-8018-7f928e5c6adf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-84151315-2a76-4e0e-8027-4a3d835d0bb9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84151315-2a76-4e0e-8027-4a3d835d0bb9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-84151315-2a76-4e0e-8027-4a3d835d0bb9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_37533663-0e75-47a2-89f2-cb4dd5e85bed\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ord_enc')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_37533663-0e75-47a2-89f2-cb4dd5e85bed button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ord_enc');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data = pd.concat([train_df, one_enc], axis=1)\n",
        "processed_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "r8MtcQd8M5cA",
        "outputId": "ec309d6f-eb43-4f40-c3c1-1a79097db550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CreditScore Geography  Gender   Age  Tenure   Balance  NumOfProducts  \\\n",
              "0               668    France    Male 33.00       3      0.00              2   \n",
              "1               627    France    Male 33.00       1      0.00              2   \n",
              "2               678    France    Male 40.00      10      0.00              2   \n",
              "3               581    France    Male 34.00       2 148882.54              1   \n",
              "4               716     Spain    Male 33.00       5      0.00              2   \n",
              "...             ...       ...     ...   ...     ...       ...            ...   \n",
              "151942          630    France    Male 50.00       8      0.00              2   \n",
              "151943          667     Spain  Female 33.00       2      0.00              1   \n",
              "151944          792    France    Male 35.00       3      0.00              1   \n",
              "151945          565    France    Male 31.00       5      0.00              1   \n",
              "151946          850    France    Male 31.00       1      0.00              1   \n",
              "\n",
              "        HasCrCard  IsActiveMember  EstimatedSalary  Exited    0    1    2  \\\n",
              "0            1.00            0.00        181449.97       0 0.00 1.00 1.00   \n",
              "1            1.00            1.00         49503.50       0 0.00 1.00 1.00   \n",
              "2            1.00            0.00        184866.69       0 0.00 1.00 1.00   \n",
              "3            1.00            1.00         84560.88       0 0.00 1.00 1.00   \n",
              "4            1.00            1.00         15068.83       0 0.00 1.00 0.00   \n",
              "...           ...             ...              ...     ...  ...  ...  ...   \n",
              "151942       1.00            1.00          5962.50       0 0.00 1.00 1.00   \n",
              "151943       1.00            1.00        131834.75       0 1.00 0.00 0.00   \n",
              "151944       0.00            0.00        131834.45       0 0.00 1.00 1.00   \n",
              "151945       1.00            1.00        127429.56       0 0.00 1.00 1.00   \n",
              "151946       1.00            0.00         61581.79       1 0.00 1.00 1.00   \n",
              "\n",
              "          3    4  \n",
              "0      0.00 0.00  \n",
              "1      0.00 0.00  \n",
              "2      0.00 0.00  \n",
              "3      0.00 0.00  \n",
              "4      0.00 1.00  \n",
              "...     ...  ...  \n",
              "151942 0.00 0.00  \n",
              "151943 0.00 1.00  \n",
              "151944 0.00 0.00  \n",
              "151945 0.00 0.00  \n",
              "151946 0.00 0.00  \n",
              "\n",
              "[151947 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af5cd198-5776-401e-866f-fa42e9a020c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>668</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>627</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>678</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>40.00</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>581</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>34.00</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>716</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151942</th>\n",
              "      <td>630</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>50.00</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>5962.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151943</th>\n",
              "      <td>667</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>33.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>131834.75</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151944</th>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>131834.45</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151945</th>\n",
              "      <td>565</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>31.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>127429.56</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151946</th>\n",
              "      <td>850</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>31.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>61581.79</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>151947 rows  16 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af5cd198-5776-401e-866f-fa42e9a020c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-af5cd198-5776-401e-866f-fa42e9a020c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-af5cd198-5776-401e-866f-fa42e9a020c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79fd1291-3a3d-4924-8fe3-82a16f136ebd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79fd1291-3a3d-4924-8fe3-82a16f136ebd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79fd1291-3a3d-4924-8fe3-82a16f136ebd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_80f86e8c-35ce-4d07-846a-489962806862\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('processed_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_80f86e8c-35ce-4d07-846a-489962806862 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('processed_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data.drop(['Geography', 'Gender'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "dOkMbLEaOXL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PerEH7BEo6iF",
        "outputId": "19816d12-4629-41f3-a7ce-56961f62fb0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore   Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
              "0          668 33.00       3      0.00              2       1.00   \n",
              "1          627 33.00       1      0.00              2       1.00   \n",
              "2          678 40.00      10      0.00              2       1.00   \n",
              "3          581 34.00       2 148882.54              1       1.00   \n",
              "4          716 33.00       5      0.00              2       1.00   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  Exited    0    1    2    3    4  \n",
              "0            0.00        181449.97       0 0.00 1.00 1.00 0.00 0.00  \n",
              "1            1.00         49503.50       0 0.00 1.00 1.00 0.00 0.00  \n",
              "2            0.00        184866.69       0 0.00 1.00 1.00 0.00 0.00  \n",
              "3            1.00         84560.88       0 0.00 1.00 1.00 0.00 0.00  \n",
              "4            1.00         15068.83       0 0.00 1.00 0.00 0.00 1.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cde79189-7ec1-428b-bb65-c891f9b345a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>668</td>\n",
              "      <td>33.00</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>181449.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>627</td>\n",
              "      <td>33.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>49503.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>678</td>\n",
              "      <td>40.00</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>184866.69</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>581</td>\n",
              "      <td>34.00</td>\n",
              "      <td>2</td>\n",
              "      <td>148882.54</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>84560.88</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>716</td>\n",
              "      <td>33.00</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>15068.83</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cde79189-7ec1-428b-bb65-c891f9b345a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cde79189-7ec1-428b-bb65-c891f9b345a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cde79189-7ec1-428b-bb65-c891f9b345a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-742a9df3-7b36-4dd6-9814-7acb363d2b74\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-742a9df3-7b36-4dd6-9814-7acb363d2b74')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-742a9df3-7b36-4dd6-9814-7acb363d2b74 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = processed_data.corr()\n",
        "correlation['Exited'].sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0JLLCsIXjYf",
        "outputId": "6635114e-86be-45c9-bba3-847035c75094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumOfProducts     -0.23\n",
              "IsActiveMember    -0.21\n",
              "1                 -0.15\n",
              "2                 -0.13\n",
              "4                 -0.05\n",
              "CreditScore       -0.03\n",
              "HasCrCard         -0.02\n",
              "Tenure            -0.02\n",
              "EstimatedSalary    0.02\n",
              "Balance            0.14\n",
              "0                  0.15\n",
              "3                  0.22\n",
              "Age                0.38\n",
              "Exited             1.00\n",
              "Name: Exited, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Train -Test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = processed_data.drop('Exited', axis=1)\n",
        "y=processed_data['Exited']\n",
        "X.columns = X.columns.astype(str)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.2, stratify =y)"
      ],
      "metadata": {
        "id": "RnwGVvJ-_YP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8Xq1XvmAEhx",
        "outputId": "f8674b3b-eaee-405a-852d-b953d756c407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    96254\n",
              "1    25303\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## treating imbalance using SMOTE technique\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state = 42)\n",
        "\n",
        "X_smote, y_smote = smote.fit_resample(X_train, y_train)"
      ],
      "metadata": {
        "id": "B3fn-Gh_Of4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_smote.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1ptpDhS3mSd",
        "outputId": "fa25805e-988f-4b91-d95b-52494c3935d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(192508, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_smote.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OrXcK5pzpu0t",
        "outputId": "f1ef2a68-7042-42d3-f453-60aa0d059920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore   Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
              "0          727 37.00       8      0.00              2       0.00   \n",
              "1          781 29.00      10      0.00              2       0.00   \n",
              "2          601 41.00       5 127302.80              2       1.00   \n",
              "3          769 30.00       2      0.00              2       1.00   \n",
              "4          649 39.00       6      0.00              2       0.00   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary    0    1    2    3    4  \n",
              "0            0.00        182630.46 1.00 0.00 1.00 0.00 0.00  \n",
              "1            0.00        172097.40 0.00 1.00 1.00 0.00 0.00  \n",
              "2            0.00         48201.64 0.00 1.00 0.00 1.00 0.00  \n",
              "3            1.00         58685.59 0.00 1.00 0.00 0.00 1.00  \n",
              "4            1.00         86767.48 0.00 1.00 1.00 0.00 0.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-617f6bd6-97f6-42c2-b1c1-69796794d0ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>727</td>\n",
              "      <td>37.00</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>182630.46</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>781</td>\n",
              "      <td>29.00</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>172097.40</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>601</td>\n",
              "      <td>41.00</td>\n",
              "      <td>5</td>\n",
              "      <td>127302.80</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>48201.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>769</td>\n",
              "      <td>30.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>58685.59</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>649</td>\n",
              "      <td>39.00</td>\n",
              "      <td>6</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>86767.48</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-617f6bd6-97f6-42c2-b1c1-69796794d0ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-617f6bd6-97f6-42c2-b1c1-69796794d0ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-617f6bd6-97f6-42c2-b1c1-69796794d0ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86d5a758-97b2-4b08-8a15-cdfd665157b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86d5a758-97b2-4b08-8a15-cdfd665157b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86d5a758-97b2-4b08-8a15-cdfd665157b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_smote.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I0C8pI-pm9Y",
        "outputId": "026dffd0-a82a-4ad6-a705-2d2ca4915786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    96254\n",
              "1    96254\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_smote.value_counts().plot.bar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "lhFG2jY1pgf3",
        "outputId": "5c3ec355-af98-4847-b213-798e2f47989f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 120
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Scaling the data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n"
      ],
      "metadata": {
        "id": "8JWiVjjjpkYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_smote.loc[:,'CreditScore':'EstimatedSalary'] = scaler.fit_transform(X_smote.loc[:,'CreditScore':'EstimatedSalary'])\n",
        "X_smote.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZiBS36_y09hi",
        "outputId": "92abbc2f-7ff6-4552-d137-83c68bea495f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   CreditScore   Age  Tenure  Balance  NumOfProducts  HasCrCard  \\\n",
              "0         0.96 -0.33    1.21    -0.93           1.11      -1.85   \n",
              "1         1.69 -1.33    1.97    -0.93           1.11      -1.85   \n",
              "2        -0.76  0.17    0.07     1.20           1.11       0.62   \n",
              "3         1.53 -1.20   -1.06    -0.93           1.11       0.62   \n",
              "4        -0.10 -0.08    0.45    -0.93           1.11      -1.85   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary    0    1    2    3    4  \n",
              "0           -0.90             1.38 1.00 0.00 1.00 0.00 0.00  \n",
              "1           -0.90             1.17 0.00 1.00 1.00 0.00 0.00  \n",
              "2           -0.90            -1.30 0.00 1.00 0.00 1.00 0.00  \n",
              "3            1.24            -1.09 0.00 1.00 0.00 0.00 1.00  \n",
              "4            1.24            -0.53 0.00 1.00 1.00 0.00 0.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0975daf-fad4-4ab6-9a9e-c6c1e7e7e7d1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.96</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>1.21</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>1.11</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>1.38</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.69</td>\n",
              "      <td>-1.33</td>\n",
              "      <td>1.97</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>1.11</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>1.17</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.76</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.07</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-1.30</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.53</td>\n",
              "      <td>-1.20</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>-1.09</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.10</td>\n",
              "      <td>-0.08</td>\n",
              "      <td>0.45</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>1.11</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>1.24</td>\n",
              "      <td>-0.53</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0975daf-fad4-4ab6-9a9e-c6c1e7e7e7d1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0975daf-fad4-4ab6-9a9e-c6c1e7e7e7d1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0975daf-fad4-4ab6-9a9e-c6c1e7e7e7d1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-77396596-0b6b-4ebd-9ed3-a04fedd19a0a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-77396596-0b6b-4ebd-9ed3-a04fedd19a0a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-77396596-0b6b-4ebd-9ed3-a04fedd19a0a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yNhp45vKzG_-",
        "outputId": "d75ef639-16e2-492c-edb6-8c90f6c2acad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CreditScore   Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
              "9861            621 30.00       2      0.00              2       0.00   \n",
              "38550           606 40.00       3  95293.86              2       1.00   \n",
              "134501          712 22.00       2 142400.77              1       1.00   \n",
              "76255           531 47.00       7      0.00              1       0.00   \n",
              "17858           727 37.00       8      0.00              2       1.00   \n",
              "\n",
              "        IsActiveMember  EstimatedSalary    0    1    2    3    4  \n",
              "9861              1.00        163516.64 0.00 1.00 1.00 0.00 0.00  \n",
              "38550             0.00         96985.58 0.00 1.00 0.00 1.00 0.00  \n",
              "134501            0.00        107876.20 0.00 1.00 1.00 0.00 0.00  \n",
              "76255             1.00        194998.34 0.00 1.00 1.00 0.00 0.00  \n",
              "17858             1.00        169863.80 1.00 0.00 1.00 0.00 0.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1fda6b91-d6ab-4740-81a4-46e7edfd32bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9861</th>\n",
              "      <td>621</td>\n",
              "      <td>30.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>163516.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38550</th>\n",
              "      <td>606</td>\n",
              "      <td>40.00</td>\n",
              "      <td>3</td>\n",
              "      <td>95293.86</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>96985.58</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134501</th>\n",
              "      <td>712</td>\n",
              "      <td>22.00</td>\n",
              "      <td>2</td>\n",
              "      <td>142400.77</td>\n",
              "      <td>1</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>107876.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76255</th>\n",
              "      <td>531</td>\n",
              "      <td>47.00</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>194998.34</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17858</th>\n",
              "      <td>727</td>\n",
              "      <td>37.00</td>\n",
              "      <td>8</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>169863.80</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1fda6b91-d6ab-4740-81a4-46e7edfd32bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1fda6b91-d6ab-4740-81a4-46e7edfd32bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1fda6b91-d6ab-4740-81a4-46e7edfd32bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2f744a6e-da1b-4e2f-9aab-f60afba079c5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2f744a6e-da1b-4e2f-9aab-f60afba079c5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2f744a6e-da1b-4e2f-9aab-f60afba079c5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.loc[:,'CreditScore':'EstimatedSalary'] =scaler.transform(X_test.loc[:,'CreditScore':'EstimatedSalary'])"
      ],
      "metadata": {
        "id": "AHpKoHqNwMQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kYOuElTX0gRE",
        "outputId": "5955d84e-17c8-4081-8dd6-a5e60e99bf54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CreditScore   Age  Tenure  Balance  NumOfProducts  HasCrCard  \\\n",
              "9861          -0.49 -1.20   -1.06    -0.93           1.11      -1.85   \n",
              "38550         -0.69  0.04   -0.68     0.66           1.11       0.62   \n",
              "134501         0.75 -2.20   -1.06     1.45          -0.77       0.62   \n",
              "76255         -1.71  0.91    0.83    -0.93          -0.77      -1.85   \n",
              "17858          0.96 -0.33    1.21    -0.93           1.11       0.62   \n",
              "\n",
              "        IsActiveMember  EstimatedSalary    0    1    2    3    4  \n",
              "9861              1.24             1.00 0.00 1.00 1.00 0.00 0.00  \n",
              "38550            -0.90            -0.33 0.00 1.00 0.00 1.00 0.00  \n",
              "134501           -0.90            -0.11 0.00 1.00 1.00 0.00 0.00  \n",
              "76255             1.24             1.62 0.00 1.00 1.00 0.00 0.00  \n",
              "17858             1.24             1.12 1.00 0.00 1.00 0.00 0.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-64ae6eab-dd5a-469d-b9ac-656c5a214352\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9861</th>\n",
              "      <td>-0.49</td>\n",
              "      <td>-1.20</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>1.11</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>1.24</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38550</th>\n",
              "      <td>-0.69</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>0.66</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134501</th>\n",
              "      <td>0.75</td>\n",
              "      <td>-2.20</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>1.45</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>-0.11</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76255</th>\n",
              "      <td>-1.71</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.83</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>-0.77</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>1.24</td>\n",
              "      <td>1.62</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17858</th>\n",
              "      <td>0.96</td>\n",
              "      <td>-0.33</td>\n",
              "      <td>1.21</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.62</td>\n",
              "      <td>1.24</td>\n",
              "      <td>1.12</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64ae6eab-dd5a-469d-b9ac-656c5a214352')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-64ae6eab-dd5a-469d-b9ac-656c5a214352 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-64ae6eab-dd5a-469d-b9ac-656c5a214352');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2d8ae08e-a84d-40ae-95b6-fa09da8a8716\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2d8ae08e-a84d-40ae-95b6-fa09da8a8716')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2d8ae08e-a84d-40ae-95b6-fa09da8a8716 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building"
      ],
      "metadata": {
        "id": "byb3cUbWsoS2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "cozeMkVCtC9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_clf =LogisticRegression(random_state=42)\n",
        "\n",
        "log_clf.fit(X_smote, y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "oFw_zVkIq48v",
        "outputId": "52754137-f721-453a-f8a6-743e0327f018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_log = log_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "w4rC1XaGuxOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Logistric Regression model ROC-AUC score: ', roc_auc_score(y_test, y_pred_log))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYKxtMOpuy1n",
        "outputId": "b1b575c3-5c20-4da4-cd42-ad4c6c8732ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistric Regression model ROC-AUC score:  0.7623377850339867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest Classifier**"
      ],
      "metadata": {
        "id": "L_K-NP5PtOPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_clf = RandomForestClassifier( random_state=42)\n",
        "rnd_clf.fit(X_smote, y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "Agkg2zQXu0wn",
        "outputId": "328cb5fa-7410-47f3-c844-0ab521b3b69f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(ccp_alpha=0.001, max_leaf_nodes=16, n_estimators=500,\n",
              "                       n_jobs=-1, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(ccp_alpha=0.001, max_leaf_nodes=16, n_estimators=500,\n",
              "                       n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(ccp_alpha=0.001, max_leaf_nodes=16, n_estimators=500,\n",
              "                       n_jobs=-1, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = rnd_clf.predict(X_test)\n",
        "print('Random Forest model ROC-AUC score: ', roc_auc_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4yzd6mEu6gJ",
        "outputId": "39222d71-e91b-48ad-cac2-b20cbd30808a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest model ROC-AUC score:  0.7627573900833944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Light GBM**"
      ],
      "metadata": {
        "id": "Ozi57BuNtUy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_clf =LGBMClassifier(random_state=42)\n",
        "lgbm_clf.fit(X_smote, y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "6RvBmvkJvBcp",
        "outputId": "a0bd57b7-bf85-435c-cd12-113044782f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 96254, number of negative: 96254\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011435 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 192508, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lgbm = lgbm_clf.predict(X_test)\n",
        "print('RLGBM model ROC-AUC score: ', roc_auc_score(y_test, y_pred_lgbm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyWUe4a4vD7e",
        "outputId": "961e2c09-bfae-4c70-9a7c-dcaf12255181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RLGBM model ROC-AUC score:  0.7732823454558526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost**"
      ],
      "metadata": {
        "id": "xGIGB29W29Qx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_clf = xgb.XGBClassifier(random_state=42)\n",
        "xgb_clf.fit(X_smote, y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "wiE2jTeD2_yV",
        "outputId": "b1123c20-7c0f-45d1-c1ed-2fcd44db753b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb = xgb_clf.predict(X_test)\n",
        "print('XGB model ROC-AUC score: ', roc_auc_score(y_test, y_pred_xgb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qzyHJ6B2_vY",
        "outputId": "4d4da5ab-1057-4f7f-b5c9-b5214e520974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB model ROC-AUC score:  0.7637443185544629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid Search for Random forest**"
      ],
      "metadata": {
        "id": "Fgk1kznotYwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_gs = {'criterion': ['entropy'],\n",
        "           'max_depth': [None, 5, 10, 15], #getting more precise within range\n",
        "           'min_samples_split': [2,5,10],\n",
        "           'max_features': [None]}\n",
        "clf = RandomForestClassifier()\n",
        "\n",
        "gs_dt = GridSearchCV(estimator = clf, param_grid =features_gs, cv = 5, scoring ='roc_auc')\n",
        "\n",
        "gs_dt.fit(X_smote,y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "mG3Kmg9ovUf9",
        "outputId": "9f0910a7-24f5-406f-bc13-5c3ef345edae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={'criterion': ['entropy'],\n",
              "                         'max_depth': [None, 5, 10, 15], 'max_features': [None],\n",
              "                         'min_samples_split': [2, 5, 10]},\n",
              "             scoring='roc_auc')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [None, 5, 10, 15], &#x27;max_features&#x27;: [None],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
              "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [None, 5, 10, 15], &#x27;max_features&#x27;: [None],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10]},\n",
              "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_dt.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_c3GM8V6hhH",
        "outputId": "fe68a8a4-8a79-4ba2-f0a0-b0407d7ec32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.964710099176866"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_dt.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LcJJWZr90Sr",
        "outputId": "bd9090c5-dfb3-4931-ed72-35cbc185007f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy',\n",
              " 'max_depth': 15,\n",
              " 'max_features': None,\n",
              " 'min_samples_split': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_roc_auc = roc_auc_score(y_test, gs_dt.predict_proba(X_test)[:, 1])\n",
        "test_roc_auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snXqZIHJ8dn_",
        "outputId": "4fdeb4aa-67b8-4dc4-e0c9-bb37b89c7503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8864055669495109"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_clf = RandomForestClassifier(criterion ='entropy', max_depth=15, max_features=None, min_samples_split=2, random_state=42)\n",
        "rnd_clf.fit(X_smote, y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "kCxsNREY9JcS",
        "outputId": "3aa54257-15d4-4e5d-9132-78280f08549d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', max_depth=15, max_features=None,\n",
              "                       random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, max_features=None,\n",
              "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=15, max_features=None,\n",
              "                       random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = rnd_clf.predict(X_test)\n",
        "print('Optimized Random Forest model ROC-AUC score: ', roc_auc_score(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiRJb-U9P9vX",
        "outputId": "31d73a12-db4b-44fb-a616-d1bb15136be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Random Forest model ROC-AUC score:  0.7681130629733924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grid Search for Light GBM**"
      ],
      "metadata": {
        "id": "xeWRpIC3tkE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_gs = {'max_depth': [None, 5, 10, 15],\n",
        "                'learning_rate': [0.05, 0.1, 0.2],\n",
        "                'min_child_samples': [20,30,40],\n",
        "                'n_estimators': [50, 100, 200],\n",
        "           'reg_alpha' : [0, 0.1, 0.5]}\n",
        "clf = LGBMClassifier(random_state=42)\n",
        "\n",
        "gs_gbm = GridSearchCV(estimator = clf, param_grid =features_gs, cv = 5, scoring ='roc_auc')\n",
        "\n",
        "gs_gbm.fit(X_smote,y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YEKF2aQVQour",
        "outputId": "9d007322-a307-48d1-bad7-a6a8e9a5b94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004809 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007130 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004760 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007519 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004502 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007126 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004431 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004853 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004439 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007646 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004599 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004637 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005373 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004520 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004792 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004479 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009706 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009927 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004517 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004366 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004680 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005775 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004612 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007265 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007617 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004548 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004837 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004738 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004665 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007491 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004456 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008355 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004638 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007653 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004593 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019090 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004664 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007611 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005759 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007238 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004688 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005754 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004705 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007325 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007470 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007178 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004507 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004598 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004649 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004525 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004406 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004606 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004711 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022446 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021176 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004792 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004745 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004537 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004513 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004525 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004413 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004517 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026521 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004596 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004528 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004590 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004737 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007016 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004400 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004868 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004794 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004663 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004784 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007213 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004547 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004493 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004392 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006733 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015317 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004644 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007258 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004677 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004654 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004560 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004661 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004721 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004586 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004852 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004906 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004538 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008392 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004540 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004683 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004404 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007151 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007485 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005445 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004642 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004579 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005011 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004487 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007769 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004520 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004504 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004651 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018830 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007206 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004384 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004513 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006514 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004720 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004479 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005472 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007192 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004695 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004501 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004701 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004476 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004423 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004791 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007595 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018244 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004440 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004578 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004860 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004583 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007219 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004679 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004422 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004439 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004623 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004543 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007183 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007660 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004547 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004787 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004875 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004466 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004726 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007574 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004711 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004550 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017718 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004695 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004845 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004476 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007907 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005612 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004651 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007693 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007164 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004448 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004421 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004472 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004568 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004661 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004593 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004373 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024308 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007407 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004584 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004455 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004529 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004749 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004688 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004698 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007308 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007279 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005176 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004645 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005000 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004456 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004531 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007209 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009324 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004535 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004522 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007937 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005374 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004389 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007341 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004687 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004690 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004671 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004572 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007226 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020333 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004498 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004520 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004766 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004747 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004441 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004416 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008110 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004705 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004516 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004529 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004424 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007264 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004686 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007882 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016575 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004567 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004825 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004596 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004509 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007461 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004552 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004844 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004455 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007301 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004534 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004522 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004502 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004380 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004560 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004696 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008078 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2056\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004485 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2052\n",
            "[LightGBM] [Info] Number of data points in the train set: 154006, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77004, number of negative: 77003\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2054\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500003 -> initscore=0.000013\n",
            "[LightGBM] [Info] Start training from score 0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 77003, number of negative: 77004\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004573 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2053\n",
            "[LightGBM] [Info] Number of data points in the train set: 154007, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499997 -> initscore=-0.000013\n",
            "[LightGBM] [Info] Start training from score -0.000013\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Number of positive: 96254, number of negative: 96254\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005588 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 192508, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LGBMClassifier(random_state=42),\n",
              "             param_grid={'learning_rate': [0.05, 0.1, 0.2],\n",
              "                         'max_depth': [None, 5, 10, 15],\n",
              "                         'min_child_samples': [20, 30, 40],\n",
              "                         'n_estimators': [50, 100, 200],\n",
              "                         'reg_alpha': [0, 0.1, 0.5]},\n",
              "             scoring='roc_auc')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(random_state=42),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
              "                         &#x27;max_depth&#x27;: [None, 5, 10, 15],\n",
              "                         &#x27;min_child_samples&#x27;: [20, 30, 40],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;reg_alpha&#x27;: [0, 0.1, 0.5]},\n",
              "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LGBMClassifier(random_state=42),\n",
              "             param_grid={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
              "                         &#x27;max_depth&#x27;: [None, 5, 10, 15],\n",
              "                         &#x27;min_child_samples&#x27;: [20, 30, 40],\n",
              "                         &#x27;n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;reg_alpha&#x27;: [0, 0.1, 0.5]},\n",
              "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_gbm.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYbqqg-ES-rG",
        "outputId": "82fc5e4a-4128-451f-b3f2-cf24fc98d592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9697581648420857"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_gbm.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sx9dGp7WTSFW",
        "outputId": "ff5d0bb4-259e-4340-af00-74f9e4a59742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.2,\n",
              " 'max_depth': 5,\n",
              " 'min_child_samples': 40,\n",
              " 'n_estimators': 200,\n",
              " 'reg_alpha': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_roc_auc = roc_auc_score(y_test, gs_gbm.predict_proba(X_test)[:, 1])\n",
        "test_roc_auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtu8QsLnTYPh",
        "outputId": "7f80b1d4-6c03-4f11-e353-c5667f1698b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8917176015975524"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {'num_leaves':16, 'learning_rate' :0.2, 'max_depth':16, 'min_child_samples':50, 'n_estimators': 200, 'reg_alpha':0.1, 'reg_lambda':0.3}"
      ],
      "metadata": {
        "id": "aaXBzLB9Ta7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_opt = LGBMClassifier(**best_params)"
      ],
      "metadata": {
        "id": "-TE3YgF45pUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_opt.fit(X_smote, y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "1LDS7ZiZ50a5",
        "outputId": "f9589913-92c0-4a00-9b72-2279c7c65df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 96254, number of negative: 96254\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2055\n",
            "[LightGBM] [Info] Number of data points in the train set: 192508, number of used features: 10\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(learning_rate=0.2, max_depth=16, min_child_samples=50,\n",
              "               n_estimators=200, num_leaves=16, reg_alpha=0.1, reg_lambda=0.3)"
            ],
            "text/html": [
              "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.2, max_depth=16, min_child_samples=50,\n",
              "               n_estimators=200, num_leaves=16, reg_alpha=0.1, reg_lambda=0.3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.2, max_depth=16, min_child_samples=50,\n",
              "               n_estimators=200, num_leaves=16, reg_alpha=0.1, reg_lambda=0.3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lgbm = lgbm_opt.predict(X_test)\n",
        "print('Optimized LGBM model ROC-AUC score: ', roc_auc_score(y_test, y_pred_lgbm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC2buXmp57V7",
        "outputId": "8e2fcf6e-02a4-46b7-f0cf-c0a11a854baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized LGBM model ROC-AUC score:  0.766977943158007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RandomizedSearch Cv** for LGBM\n",
        "\n"
      ],
      "metadata": {
        "id": "m4Xp8m1mZ40_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_rs = { 'num_leaves' : [20,30],\n",
        "                'max_depth': [-1, 5, 10, 15],\n",
        "                'learning_rate': [0.05, 0.1, 0.2],\n",
        "                'min_child_samples': [20,30,40],\n",
        "                'n_estimators': [50, 100, 200],\n",
        "                'reg_alpha' : [0, 0.1, 0.5],\n",
        "                'reg_lambda':[0, 0.1, 0.5]}\n",
        "clf = LGBMClassifier(random_state=42)\n",
        "\n",
        "rs_gbm = RandomizedSearchCV(estimator = clf, param_distributions=features_rs, n_iter=100, cv = 3, scoring ='roc_auc', random_state=42)\n",
        "\n",
        "rs_gbm.fit(X_smote,y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iG-V0GXGZE1_",
        "outputId": "55c3c449-d5f3-478b-8c73-a614696da744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011548 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018023 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011742 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010813 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011035 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011030 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011158 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023248 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011395 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016625 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013173 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010606 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010962 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037126 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011775 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011240 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016442 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022889 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010735 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014764 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011485 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011933 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010850 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011867 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011373 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010938 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010786 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011313 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010759 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011142 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023086 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010872 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011225 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011031 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011384 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012182 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011464 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011424 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011727 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011830 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011316 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012137 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011359 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010639 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010802 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010827 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022453 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011554 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011025 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016464 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010611 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011411 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011164 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011431 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011452 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017785 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013526 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013682 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011782 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011427 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011184 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015262 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010907 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011555 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011235 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013383 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011415 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016756 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011583 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012120 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011612 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014821 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011387 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016657 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011233 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011515 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011853 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017189 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011532 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011319 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011295 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016557 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010768 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010866 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011116 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011743 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011327 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016555 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011742 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010743 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010607 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011718 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010587 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010751 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016560 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010985 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010783 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011624 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011470 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010977 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011238 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010828 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010763 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011421 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011552 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017733 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011388 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011783 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011586 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011304 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011908 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013453 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011359 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010937 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012062 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016563 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010745 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011240 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011546 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011022 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011430 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010828 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011134 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011663 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016475 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011357 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011831 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010787 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011317 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025539 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012139 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011229 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012485 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010915 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011635 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011861 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011255 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011691 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012039 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010755 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017186 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012706 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011010 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011647 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023465 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032943 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010876 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011524 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011011 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011971 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011529 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016239 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010845 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012025 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016927 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012591 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010857 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010957 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011468 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011778 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011080 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011133 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011902 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010921 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010600 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011910 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010747 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010931 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016439 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017323 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012384 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010950 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012690 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012704 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011373 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016507 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010864 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011563 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011618 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011405 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011808 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017161 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012881 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011448 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012245 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011326 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011430 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012050 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011383 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016915 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011589 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011070 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011326 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011678 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011008 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011183 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011687 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021559 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014965 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010655 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011894 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011284 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011157 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011087 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010966 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011075 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022811 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011272 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011190 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011542 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016547 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010896 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011197 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010933 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012070 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010851 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010823 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015041 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010438 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011607 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015971 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010767 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014251 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016342 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010969 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011666 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022075 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010640 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011823 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011107 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011903 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010975 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012042 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015669 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011108 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012502 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011142 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011203 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017366 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011027 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011588 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016859 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011164 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010698 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016549 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011664 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010829 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011257 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018044 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011594 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010748 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010906 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016829 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019296 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011908 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012150 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011073 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012505 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015274 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016165 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011231 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011683 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017841 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010971 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023006 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011368 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2822\n",
            "[LightGBM] [Info] Number of data points in the train set: 128338, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "[LightGBM] [Info] Number of positive: 64170, number of negative: 64169\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016427 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2821\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500004 -> initscore=0.000016\n",
            "[LightGBM] [Info] Start training from score 0.000016\n",
            "[LightGBM] [Info] Number of positive: 64169, number of negative: 64170\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011369 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 128339, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499996 -> initscore=-0.000016\n",
            "[LightGBM] [Info] Start training from score -0.000016\n",
            "[LightGBM] [Info] Number of positive: 96254, number of negative: 96254\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016631 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 192508, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, estimator=LGBMClassifier(random_state=42), n_iter=100,\n",
              "                   param_distributions={'learning_rate': [0.05, 0.1, 0.2],\n",
              "                                        'max_depth': [-1, 5, 10, 15],\n",
              "                                        'min_child_samples': [20, 30, 40],\n",
              "                                        'n_estimators': [50, 100, 200],\n",
              "                                        'num_leaves': [20, 30],\n",
              "                                        'reg_alpha': [0, 0.1, 0.5],\n",
              "                                        'reg_lambda': [0, 0.1, 0.5]},\n",
              "                   random_state=42, scoring='roc_auc')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3, estimator=LGBMClassifier(random_state=42), n_iter=100,\n",
              "                   param_distributions={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
              "                                        &#x27;max_depth&#x27;: [-1, 5, 10, 15],\n",
              "                                        &#x27;min_child_samples&#x27;: [20, 30, 40],\n",
              "                                        &#x27;n_estimators&#x27;: [50, 100, 200],\n",
              "                                        &#x27;num_leaves&#x27;: [20, 30],\n",
              "                                        &#x27;reg_alpha&#x27;: [0, 0.1, 0.5],\n",
              "                                        &#x27;reg_lambda&#x27;: [0, 0.1, 0.5]},\n",
              "                   random_state=42, scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3, estimator=LGBMClassifier(random_state=42), n_iter=100,\n",
              "                   param_distributions={&#x27;learning_rate&#x27;: [0.05, 0.1, 0.2],\n",
              "                                        &#x27;max_depth&#x27;: [-1, 5, 10, 15],\n",
              "                                        &#x27;min_child_samples&#x27;: [20, 30, 40],\n",
              "                                        &#x27;n_estimators&#x27;: [50, 100, 200],\n",
              "                                        &#x27;num_leaves&#x27;: [20, 30],\n",
              "                                        &#x27;reg_alpha&#x27;: [0, 0.1, 0.5],\n",
              "                                        &#x27;reg_lambda&#x27;: [0, 0.1, 0.5]},\n",
              "                   random_state=42, scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rs_gbm.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDBH3nhfeQg-",
        "outputId": "977a8c7c-0834-48c7-8e59-8bf42bef4c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9646368844884806"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rs_gbm.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cfu2qNbeQUP",
        "outputId": "1851c4a7-8600-40e7-eb4c-34f14af329fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'reg_lambda': 0,\n",
              " 'reg_alpha': 0.5,\n",
              " 'num_leaves': 30,\n",
              " 'n_estimators': 200,\n",
              " 'min_child_samples': 40,\n",
              " 'max_depth': -1,\n",
              " 'learning_rate': 0.1}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = { 'learning_rate' :0.1, 'max_depth':None, 'min_child_samples':40, 'n_estimators': 200, 'reg_alpha':0.5, 'reg_lambda':0, 'num_leaves':30,'max_depth':-1}"
      ],
      "metadata": {
        "id": "VQFxH8wUeQLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_opt = LGBMClassifier(**best_params)"
      ],
      "metadata": {
        "id": "_W8kxY7IgDKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_opt.fit(X_smote, y_smote)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "ktcwRONQgF_u",
        "outputId": "0833152f-31af-4ecd-a56b-e6628613cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 96254, number of negative: 96254\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019502 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2819\n",
            "[LightGBM] [Info] Number of data points in the train set: 192508, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(min_child_samples=40, n_estimators=200, num_leaves=30,\n",
              "               reg_alpha=0.5, reg_lambda=0)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(min_child_samples=40, n_estimators=200, num_leaves=30,\n",
              "               reg_alpha=0.5, reg_lambda=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(min_child_samples=40, n_estimators=200, num_leaves=30,\n",
              "               reg_alpha=0.5, reg_lambda=0)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_lgbm = lgbm_opt.predict(X_test)\n",
        "print('Optimized LGBM model ROC-AUC score: ', roc_auc_score(y_test, y_pred_lgbm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-o1jyMLgJLW",
        "outputId": "bc63ba73-7b96-4199-851e-4b4fd23d30f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized LGBM model ROC-AUC score:  0.7672582710726922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Final model"
      ],
      "metadata": {
        "id": "oZ4EaMBK-PGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Test data processing\n",
        "\n",
        "\n",
        "def test_prep(df):\n",
        "\n",
        "    test =test_df.drop(['CustomerId', 'Surname'], axis=1)\n",
        "\n",
        "    ##getting index columns\n",
        "\n",
        "    idx = test.index\n",
        "    # ordinal encoding\n",
        "    data = test[['Gender', 'Geography']]\n",
        "\n",
        "    result = encoder.transform(data)\n",
        "    one_enc =pd.DataFrame(result)\n",
        "\n",
        "    one_enc.index=idx\n",
        "\n",
        "    data_comb = pd.concat([test, one_enc], axis=1)\n",
        "\n",
        "    data2 = data_comb.drop(['Geography', 'Gender'], axis=1)\n",
        "\n",
        "    # Scaling\n",
        "\n",
        "    data2.loc[:,'CreditScore':'EstimatedSalary'] =scaler.transform(data2.loc[:,'CreditScore':'EstimatedSalary'])\n",
        "\n",
        "    return data2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2evIE3-g-27y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data =test_prep(test_df)"
      ],
      "metadata": {
        "id": "9UCZn7D-DEYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "dTlEdaLSIIGX",
        "outputId": "7018aff2-9436-4453-f010-3f4743915d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        CreditScore   Age  Tenure  Balance  NumOfProducts  HasCrCard  \\\n",
              "id                                                                     \n",
              "165034        -0.97 -2.08   -1.06    -0.93           1.11      -1.85   \n",
              "165035         0.35  0.79   -1.06    -0.93          -0.76       0.62   \n",
              "165036        -0.02 -0.71    0.83    -0.93           1.11       0.62   \n",
              "165037         0.32 -0.46    1.21    -0.93          -0.76       0.62   \n",
              "165038         1.29 -0.21    1.96     1.10          -0.76       0.62   \n",
              "\n",
              "        IsActiveMember  EstimatedSalary    0    1    2    3    4  \n",
              "id                                                                \n",
              "165034            1.25             0.95 1.00 0.00 1.00 0.00 0.00  \n",
              "165035           -0.89            -0.81 1.00 0.00 1.00 0.00 0.00  \n",
              "165036           -0.89             0.51 1.00 0.00 1.00 0.00 0.00  \n",
              "165037           -0.89             0.01 0.00 1.00 1.00 0.00 0.00  \n",
              "165038           -0.89             0.52 0.00 1.00 0.00 1.00 0.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-175dde26-0001-4033-8f3f-9a82160bf670\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>165034</th>\n",
              "      <td>-0.97</td>\n",
              "      <td>-2.08</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>1.11</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.95</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165035</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.79</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.89</td>\n",
              "      <td>-0.81</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165036</th>\n",
              "      <td>-0.02</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>0.83</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>1.11</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.89</td>\n",
              "      <td>0.51</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165037</th>\n",
              "      <td>0.32</td>\n",
              "      <td>-0.46</td>\n",
              "      <td>1.21</td>\n",
              "      <td>-0.93</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.89</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165038</th>\n",
              "      <td>1.29</td>\n",
              "      <td>-0.21</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1.10</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>0.62</td>\n",
              "      <td>-0.89</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-175dde26-0001-4033-8f3f-9a82160bf670')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-175dde26-0001-4033-8f3f-9a82160bf670 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-175dde26-0001-4033-8f3f-9a82160bf670');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-165f97e9-1598-4e25-9a97-4849e8cb3f24\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-165f97e9-1598-4e25-9a97-4849e8cb3f24')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-165f97e9-1598-4e25-9a97-4849e8cb3f24 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = lgbm_opt"
      ],
      "metadata": {
        "id": "yTkfzIdmIJ2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_col = final_model.predict_proba(test_data)[:,1]"
      ],
      "metadata": {
        "id": "DLmrnwo3Ibq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['Prediction'] = y_col"
      ],
      "metadata": {
        "id": "GLQBb72aIowP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['Prediction']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L-g5AogIzFX",
        "outputId": "dbe28e2a-a4ec-42e2-9c3b-ce86facfd0aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "165034   0.04\n",
              "165035   0.86\n",
              "165036   0.03\n",
              "165037   0.23\n",
              "165038   0.35\n",
              "         ... \n",
              "275052   0.04\n",
              "275053   0.08\n",
              "275054   0.02\n",
              "275055   0.15\n",
              "275056   0.13\n",
              "Name: Prediction, Length: 110023, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZdbrfuxXI1lI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}